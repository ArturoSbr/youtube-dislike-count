{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19693b80",
   "metadata": {
    "id": "19693b80"
   },
   "source": [
    "# Analysis\n",
    "\n",
    "This notebook creates features from raw tables, runs multiple regressions and visualizes the results.\n",
    "\n",
    "## 1. Set environment\n",
    "\n",
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17591853",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17591853",
    "outputId": "e919d802-8ac8-465d-9f60-e555f75b91b7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import floor\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import statsmodels.api as sm\n",
    "from isodate import parse_duration\n",
    "from scipy.stats import ttest_ind\n",
    "from stargazer.stargazer import Stargazer\n",
    "\n",
    "# Constantly changing\n",
    "from disco import cv_bandwidth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e10a6b",
   "metadata": {},
   "source": [
    "The following cell parses json files. Avoid running it again."
   ]
  },
  {
   "cell_type": "raw",
   "id": "aaacf8f1",
   "metadata": {},
   "source": [
    "# Imports for this cell\n",
    "import os\n",
    "import json\n",
    "\n",
    "# List of all files\n",
    "files = [file for file in os.listdir('../../dat/comments/') if '.json' in file]\n",
    "\n",
    "# Count all comments scraped\n",
    "allComments = 0\n",
    "for file in files:\n",
    "    cs = json.load(open(f'../../dat/comments/{file}'))\n",
    "    allComments += len(\n",
    "        cs.get(\n",
    "            file.replace('.json', '')\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Results\n",
    "print(f'Number of videos with at least one comment in first 12 hours:{len(files)}') # 1,846\n",
    "print(f'Number of comments scraped: {allComments}') # 1,197,454"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee4cd6e",
   "metadata": {},
   "source": [
    "Counts:\n",
    "- All videos\n",
    "    - 1,928\n",
    "- All videos with at least one comment in first 12 hours\n",
    "    - 1,846\n",
    "- All videos with at least one comment in English in first 12 hours\n",
    "    - 1,814\n",
    "- All videos with at least one comment in first 12 hours and excluding fuzzy window\n",
    "    - 1516\n",
    "- All videos with at least one comment in English in first 12 hours excluding fuzzy window\n",
    "    - 1504\n",
    "- All comments\n",
    "    - 1,197,454"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78b141c",
   "metadata": {
    "id": "b78b141c"
   },
   "source": [
    "Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178a85ed",
   "metadata": {
    "id": "178a85ed"
   },
   "outputs": [],
   "source": [
    "# Video details table\n",
    "d1 = pd.read_csv('../../dat/videoDetails.csv')\n",
    "\n",
    "# Classified comments\n",
    "# d2 = pd.read_csv('../../dat/videoFlags.csv') # Deprecated (no langid filter & no Nov-10 data)\n",
    "# d2 = pd.read_csv('../../dat/videoFlagsFuzzy.csv') # Deprecated (no langid filter)\n",
    "d2 = pd.read_csv('../../dat/videoFlagsFuzzyLangid.csv') # Current (has langid filter and Nov-10 data)\n",
    "\n",
    "# Create dataframe for analysis\n",
    "df = pd.merge(d1, d2, on='videoId', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1abc6e",
   "metadata": {},
   "source": [
    "Create masks for each time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b88dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert publishedAt to timestamp\n",
    "df['publishedAt'] = pd.to_datetime(df['publishedAt'], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "# Sort data by upload date\n",
    "df = df.sort_values('publishedAt', ascending=True).reset_index(drop=True)\n",
    "\n",
    "# Start of policy rollout (Nov 10)\n",
    "start = pd.Timestamp('2021-11-10 00:00:00')\n",
    "\n",
    "# Start of post period (Nov 11)\n",
    "postStart = start + pd.Timedelta(hours=24)\n",
    "\n",
    "# Time windows\n",
    "hours = np.arange(12, 72+1, 12)         # [12, 24, ..., 72]\n",
    "windows = [f'Post{h}' for h in hours]   # [Post12, Post24, ..., Post72]\n",
    "\n",
    "# Init dict in which to store masks\n",
    "donuts = {}\n",
    "\n",
    "\n",
    "# Create masks for each time window\n",
    "for h in hours:\n",
    "\n",
    "    # Set max time of upload before treatment\n",
    "    lim = start - pd.Timedelta(hours=h)\n",
    "\n",
    "    # Pre-treatment or post-treatment mask (h: mask)\n",
    "    donuts[h] = df['publishedAt'].le(lim) | df['publishedAt'].ge(postStart)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c563fb",
   "metadata": {
    "id": "75c563fb"
   },
   "source": [
    "## 2. Feature engineering\n",
    "Turn `definition` to dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74a69d2",
   "metadata": {
    "id": "b74a69d2"
   },
   "outputs": [],
   "source": [
    "df['definition'] = df['definition'].replace({'sd':'0','hd':'1'}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67536050",
   "metadata": {
    "id": "67536050"
   },
   "source": [
    "Create means from counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b37125f",
   "metadata": {
    "id": "2b37125f"
   },
   "outputs": [],
   "source": [
    "# Create per-video means\n",
    "for h in hours:\n",
    "\n",
    "    # NCRs\n",
    "    df[f'ncr1Post{h}'] = df[f'post{h}CommentsNeg1'] / df[f'post{h}CommentsNum'].replace(0, 1)\n",
    "    df[f'ncr2Post{h}'] = df[f'post{h}CommentsNeg2'] / df[f'post{h}CommentsNum'].replace(0, 1)\n",
    "    \n",
    "    # PCRs\n",
    "    df[f'pcr1Post{h}'] = df[f'post{h}CommentsPos1'] / df[f'post{h}CommentsNum'].replace(0, 1)\n",
    "    df[f'pcr2Post{h}'] = df[f'post{h}CommentsPos2'] / df[f'post{h}CommentsNum'].replace(0, 1)\n",
    "    \n",
    "    # Relative ratios (constraint: at least one of each)\n",
    "    df[f'rel1Post{h}'] = np.where(\n",
    "        df[f'post{h}CommentsNeg1'].gt(0) & df[f'post{h}CommentsPos1'].gt(0),\n",
    "        df[f'post{h}CommentsNeg1'] / df[f'post{h}CommentsPos1'],\n",
    "        np.nan\n",
    "    )\n",
    "    df[f'rel2Post{h}'] = np.where(\n",
    "        df[f'post{h}CommentsNeg2'].gt(0) & df[f'post{h}CommentsPos2'].gt(0),\n",
    "        df[f'post{h}CommentsNeg2'] / df[f'post{h}CommentsPos2'],\n",
    "        np.nan\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a5c574",
   "metadata": {
    "id": "53a5c574"
   },
   "source": [
    "Analyze most important words in video titles to create dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3156b940",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "3156b940",
    "outputId": "e2ad3e11-0d95-4528-d39b-5d0771ecc114"
   },
   "outputs": [],
   "source": [
    "# All titles to single text\n",
    "text = ' '.join(df['title'].str.title().tolist())\n",
    "\n",
    "# Remove annoying strings\n",
    "for string in [\"'s\",\".\",\"-\"]:\n",
    "    text = text.replace(string, '')\n",
    "\n",
    "# All words to uppercase\n",
    "text = text.upper()\n",
    "\n",
    "# Stopwords\n",
    "stopwords = set(list(STOPWORDS) + ['SAY','SAYS','S'])\n",
    "\n",
    "# Plot wordcloud\n",
    "wordcloud = WordCloud(\n",
    "    background_color='white',\n",
    "    max_words=25,\n",
    "    stopwords=stopwords,\n",
    "    max_font_size=40, \n",
    "    scale=3,\n",
    "    random_state=42\n",
    ").generate(text)\n",
    "\n",
    "# Show wordcloud\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "plt.axis('off')\n",
    "plt.imshow(wordcloud)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65939766",
   "metadata": {},
   "source": [
    "Create dummy variables by topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f56b12",
   "metadata": {
    "id": "10f56b12"
   },
   "outputs": [],
   "source": [
    "# Title to lowercase\n",
    "df['title'] = df['title'].str.lower()\n",
    "\n",
    "# Dictionary of keywords\n",
    "topics = {\n",
    "    'biden':'biden',\n",
    "    'trump':'trump',\n",
    "    'president':'biden|trump',\n",
    "    'climate':'cop26|cop 26|climate',\n",
    "    'economy':'inflation|infrastructure|econom',\n",
    "    'covid':'covid|covid19|covid-19|virus',\n",
    "    'violence':'kill|murder|assassin| die| dead| shoot| shot'\n",
    "}\n",
    "\n",
    "# Create Indicator variables\n",
    "for topic in topics.keys():\n",
    "    df[topic] = np.where(df['title'].str.contains(topics[topic]), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6b285d",
   "metadata": {
    "id": "2e6b285d"
   },
   "source": [
    "Video title sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83289431",
   "metadata": {
    "id": "83289431"
   },
   "outputs": [],
   "source": [
    "clf = SentimentIntensityAnalyzer()\n",
    "df['toneCom'] = df['title'].apply(lambda x: clf.polarity_scores(x)['compound'])\n",
    "df['tonePos'] = df['title'].apply(lambda x: clf.polarity_scores(x)['pos'])\n",
    "df['toneNeg'] = df['title'].apply(lambda x: clf.polarity_scores(x)['neg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba47247d",
   "metadata": {
    "id": "ba47247d"
   },
   "source": [
    "Translate `duration` to seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471d484e",
   "metadata": {
    "id": "471d484e"
   },
   "outputs": [],
   "source": [
    "# YT-duration format to seconds\n",
    "df['seconds'] = df['duration'].apply(lambda x: int(parse_duration(x).total_seconds()))\n",
    "\n",
    "# log(seconds)\n",
    "df['logSeconds'] = np.log(df['seconds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79daa2da",
   "metadata": {
    "id": "79daa2da"
   },
   "source": [
    "Treatment indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a317e68b",
   "metadata": {
    "id": "a317e68b"
   },
   "outputs": [],
   "source": [
    "df['treat'] = df['publishedAt'].ge(start).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71750b13",
   "metadata": {
    "id": "71750b13"
   },
   "source": [
    "Declare running variable $R_i$ and interaction term $R_i \\times T_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c4df5",
   "metadata": {
    "id": "6f3c4df5"
   },
   "outputs": [],
   "source": [
    "# Running variable\n",
    "df['r'] = (df['publishedAt'] - start).dt.total_seconds()\n",
    "\n",
    "# Interaction\n",
    "df['rTreat'] = df['r'].multiply(df['treat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b283eaad",
   "metadata": {
    "id": "b283eaad"
   },
   "source": [
    "## 3. Descriptive Statistics\n",
    "\n",
    "### Counts\n",
    "\n",
    "Number of available videos as a function of $h$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9718a7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "a9718a7d",
    "outputId": "5c16e638-831e-45ac-af65-8a8a3c45e0b7"
   },
   "outputs": [],
   "source": [
    "# Init list\n",
    "d = []\n",
    "\n",
    "# Iterate over time windows\n",
    "for h in hours:\n",
    "\n",
    "    # Append case, before, after and total\n",
    "    d.append(\n",
    "        [\n",
    "            h,\n",
    "            f'{h+24} hours',\n",
    "            (df['publishedAt'].le(start - pd.Timedelta(hours=h)) & df[f'post{h}CommentsNum'].gt(0)).sum(),\n",
    "            (df['publishedAt'].ge(postStart) & df[f'post{h}CommentsNum'].gt(0)).sum(),\n",
    "            (donuts[h] & df[f'post{h}CommentsNum'].gt(0)).sum()\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# To dataframe\n",
    "d = pd.DataFrame(data=d, columns=['h','Donut Hole', 'Before', 'After', 'Total'])\n",
    "\n",
    "# View\n",
    "d\n",
    "# print(\n",
    "#     d.to_latex(\n",
    "#         caption='Number of available videos',\n",
    "#         label='tab_dat_nObs',\n",
    "#         index=False\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df25858b",
   "metadata": {
    "id": "df25858b"
   },
   "source": [
    "### Balance tests\n",
    "\n",
    "Balance table using a linear stepwise design and excluding the donut hole for $h = 12$.\n",
    "\n",
    "$$X_i = \\gamma_0 + \\gamma_1 r_i + \\gamma_2 T_i + \\gamma_3 (r_i \\times T_i) + V_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82bd8c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "b82bd8c2",
    "outputId": "c6f5dd0b-864a-4ebf-8fbe-2449e36addbf"
   },
   "outputs": [],
   "source": [
    "# Copy data\n",
    "d = df.copy()\n",
    "\n",
    "# Create video length (minutes)\n",
    "d['durationMins'] = d['seconds'].div(60)\n",
    "\n",
    "# Order frequent-word variables by frequency\n",
    "X = list(topics.keys()) + ['definition','durationMins','tonePos','toneNeg','toneCom']\n",
    "\n",
    "# Regress each variable on r and treat\n",
    "data = []\n",
    "for x in X:\n",
    "    m = sm.OLS.from_formula(\n",
    "        formula=f'{x} ~ r + treat + I(r*treat)',\n",
    "        data=d,\n",
    "    ).fit(cov_type='HC0')\n",
    "    data.append((m.params['treat'], m.pvalues['treat']))\n",
    "\n",
    "# Summary table\n",
    "t = pd.DataFrame(data=data, index=X, columns=['Estimated Value','p-value'])\n",
    "t.index.rename('Covariate', inplace=True)\n",
    "t.reset_index(inplace=True)\n",
    "\n",
    "# Print exog that did not pass balance test\n",
    "print(\n",
    "    'Variables that did not pass: \\n',\n",
    "    t.loc[t['p-value'].lt(0.1),\n",
    "    'Covariate'], sep=''\n",
    ")\n",
    "\n",
    "# View\n",
    "t.round(3)\n",
    "\n",
    "# To latex\n",
    "# print(\n",
    "#     t.to_latex(\n",
    "#         caption='Regression discontinuities on observable characteristics',\n",
    "#         label='tab_dat_balance',\n",
    "#         float_format='%.3f',\n",
    "#         index=False\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d677e",
   "metadata": {
    "id": "4f5d677e"
   },
   "source": [
    "## 4. Regression Analysis\n",
    "\n",
    "Convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368226f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stars function\n",
    "def stars(pval):\n",
    "    if pval <= 0.01:\n",
    "        return '***'\n",
    "    elif pval <= 0.05:\n",
    "        return '**'\n",
    "    elif pval <= 0.1:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# Function to extract most relevant info from RDD\n",
    "def get_info(models, dep_vars, hours):\n",
    "\n",
    "    # Form dataframe\n",
    "    t =  pd.DataFrame(\n",
    "        {\n",
    "            # Targets\n",
    "            'y':np.repeat(dep_vars, len(hours)),\n",
    "            # Time windows\n",
    "            'h':list(hours)*len(dep_vars),\n",
    "            # Betas\n",
    "            'T':[models[i].params['treat'] for i in range(len(models))],\n",
    "            # Standard errors\n",
    "            'se':[models[i].bse['treat'] for i in range(len(models))],\n",
    "            # p-values\n",
    "            'pval':[models[i].pvalues['treat'] for i in range(len(models))],\n",
    "            # Significance\n",
    "            'signif':[stars(models[i].pvalues['treat']) for i in range(len(models))],\n",
    "            # Mean at r=0\n",
    "            'mean':[models[i].predict({'r':0, 'treat':0}).item() for i in range(len(models))],\n",
    "            # R2\n",
    "            'R2':[models[i].rsquared for i in range(len(models))],\n",
    "            # Number of observations\n",
    "            'nobs':[int(models[i].nobs) for i in range(len(models))]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Reindex table\n",
    "    return t.set_index(['y', 'h'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9769ad5",
   "metadata": {},
   "source": [
    "### 4.1. Fit models\n",
    "The following models consider a donut hole as a funtion of $h$.\n",
    "\n",
    "`d1:` $Y_i = \\beta_0 + \\beta_1 r_i + \\beta_2 T_i + \\beta_3 (T_i \\times r_i) + U_i$\n",
    "\n",
    "`d2:` $Y_i = \\beta_0 + \\beta_1 r_i + \\beta_2 r_i^2 + \\beta_3 T_i + \\beta_4 (T_i \\times r_i) + \\beta_5 (T_i \\times r_i)^2 + V_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b351ad",
   "metadata": {
    "id": "b2b351ad",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rename post{H}CommentsNum to make it compatible\n",
    "for col in df.columns:\n",
    "    if 'CommentsNum' in col:\n",
    "        df.rename(\n",
    "            columns={col:f'commentsNum{col[:6].title()}'},\n",
    "            inplace=True\n",
    "        )\n",
    "\n",
    "# Minimum number of comments in each video\n",
    "min_comments = 0\n",
    "\n",
    "# Empty lists to store results in\n",
    "d1, d2 = [], []\n",
    "\n",
    "# Iterate over targets\n",
    "for target in ['ncr1', 'ncr2', 'pcr1', 'pcr2', 'rel1', 'rel2', 'commentsNum']:\n",
    "\n",
    "    # Iterate over Post%H windows\n",
    "    for h, post in zip(hours, windows):\n",
    "\n",
    "        # Masks for `rel1` & `rel2`\n",
    "        if 'rel' in target:\n",
    "            mask = donuts[h] & df[f'{target}{post}'].notna()\n",
    "        \n",
    "        # Masks for `ncr`, `pcr` and `commentsNum`\n",
    "        else:\n",
    "            mask = donuts[h] & df[f'commentsNum{post}'].gt(min_comments)\n",
    "\n",
    "        # Linear and quad formulas for post{h}CommentsNum\n",
    "        p1 = f'{target}{post} ~ treat + r + I(r*treat)'\n",
    "        p2 = f'{target}{post} ~ treat + r + I(r**2) + I(r*treat) + I((r*treat)**2)'\n",
    "\n",
    "        # Fit models\n",
    "        m1 = sm.OLS.from_formula(formula=p1, data=df[mask]).fit(cov_type='HC0')\n",
    "        m2 = sm.OLS.from_formula(formula=p2, data=df[mask]).fit(cov_type='HC0')\n",
    "\n",
    "        # Append to list\n",
    "        d1.append(m1)\n",
    "        d2.append(m2)\n",
    "\n",
    "# Create summary tables\n",
    "d1Res = get_info(d1, ['ncr1', 'ncr2', 'pcr1', 'pcr2', 'rel1', 'rel2', 'commentsNum'], hours)\n",
    "d2Res = get_info(d2, ['ncr1', 'ncr2', 'pcr1', 'pcr2', 'rel1', 'rel2', 'commentsNum'], hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbe456b",
   "metadata": {},
   "source": [
    "View results from linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b83524",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results\n",
    "d1Res.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab6399d3",
   "metadata": {},
   "source": [
    "Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cce554e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose depvar\n",
    "y = 'ncr2'\n",
    "\n",
    "# Format table\n",
    "res = d1Res[d1Res.index.get_level_values(0) == y].reset_index()\n",
    "res = res[[col for col in res.columns if col not in ('y', 'R2')]]\n",
    "res['diff'] = res['T'].div(res['mean'], axis=0) * 100\n",
    "res = res[['h','T','se','pval','signif','mean','diff','nobs']]\n",
    "\n",
    "# View\n",
    "# res.round(3)\n",
    "# print(\n",
    "#         res.to_latex(\n",
    "#         index=False,\n",
    "#         float_format='%.3f',\n",
    "#         caption=f'Estimated effects on {y}',\n",
    "#         label=f'tab_res_{y}'\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb054ec",
   "metadata": {},
   "source": [
    "View results from quadratic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3960da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View\n",
    "d2Res.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9926ce5e",
   "metadata": {},
   "source": [
    "### 4.2. Robustness checks\n",
    "\n",
    "#### 4.2.1. Fit linear models without donut hole\n",
    "Ignore donut holes and consider treatment at `2021-11-10 00:00:00`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ccb88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty lists to store results in\n",
    "r1 = []\n",
    "\n",
    "# List of targets\n",
    "targets = ['ncr1', 'ncr2'] # + ['pcr1', 'pcr2', 'rel1', 'rel2','commentsNum']\n",
    "\n",
    "# Iterate over targets\n",
    "for target in targets:\n",
    "\n",
    "    # Iterate over Post%H windows\n",
    "    for h, post in zip(hours, windows):\n",
    "\n",
    "        # Mask commentsNumPost{h} > 0)\n",
    "        mask = df[f'commentsNum{post}'] > 0\n",
    "\n",
    "        # Formula for first-degree polynomial\n",
    "        p1 = f'{target}{post} ~ treat + r + I(r*treat)'\n",
    "\n",
    "        # Fit models\n",
    "        m1 = sm.OLS.from_formula(\n",
    "            formula=p1,\n",
    "            data=df[mask]\n",
    "        ).fit(cov_type='HC0')\n",
    "\n",
    "        # Append to list\n",
    "        r1.append(m1)\n",
    "\n",
    "# Get results\n",
    "r1Res = get_info(r1, targets, hours)\n",
    "\n",
    "# View results\n",
    "r1Res.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e0d43cd",
   "metadata": {},
   "source": [
    "Print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f78f3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 'ncr2'\n",
    "res = r1Res[r1Res.index.get_level_values(0) == y].copy()\n",
    "res['diff'] = res['T'].div(res['mean']) * 100\n",
    "res = res.reset_index()[['h','T','se','pval','mean','diff','nobs']]\n",
    "res\n",
    "# print(\n",
    "#     res.to_latex(\n",
    "#         index=False,\n",
    "#         float_format='%.3f',\n",
    "#         caption=f'Estimated effects on {y}',\n",
    "#         label=f'tab_res_rob1_{y}'\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b771f1d6",
   "metadata": {},
   "source": [
    "#### 4.2.2. Linear models with optimum bandwidth\n",
    "Find MSE-optimal bandwidth using cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b087313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init list to store results from CVs in\n",
    "cvs = []\n",
    "\n",
    "# Iterate over targets\n",
    "for target in targets:\n",
    "\n",
    "    # Iterate over time windows\n",
    "    for hour in hours:\n",
    "\n",
    "        # Custom bandwidths for each time period (plus some pad)\n",
    "        pad = 6\n",
    "        bws = [(60**2)*h for h in np.arange(-144, 144+1) if abs(h) >= max(abs(hour), 24)+pad]\n",
    "\n",
    "        # Data that excludes donut hole\n",
    "        t = df[donuts[hour] & df[f'commentsNumPost{hour}'].gt(min_comments)].copy()\n",
    "\n",
    "        # CV process\n",
    "        cv = cv_bandwidth(\n",
    "            data=t,\n",
    "            dependent_variable=f'{target}Post{hour}',\n",
    "            running_variable='r',\n",
    "            cutoff=0,\n",
    "            treated='above',\n",
    "            degree=1,\n",
    "            bandwidths=bws,\n",
    "            folds=10,\n",
    "            criteria='mse',\n",
    "            random_state=42\n",
    "        )\n",
    "\n",
    "        # Sort by MSE DESC\n",
    "        cv.sort_values('cvScore', ascending=False, inplace=True)\n",
    "\n",
    "        # Convert bounds to hours\n",
    "        cv[['lowerBoundH', 'upperBoundH']] = cv[['lowerBound', 'upperBound']].div(60**2).astype(int)\n",
    "\n",
    "        # Add window column\n",
    "        cv['window'] = hour\n",
    "\n",
    "        # Append to list\n",
    "        cvs.append(cv)\n",
    "\n",
    "# Best bw for each target & window\n",
    "opt_ncr1 = pd.concat(\n",
    "    [cvs[i].head(1) for i in range(len(cvs)) if i < 6]\n",
    ")\n",
    "opt_ncr2 = pd.concat(\n",
    "    [cvs[i].head(1) for i in range(len(cvs)) if i >= 6]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925103b8",
   "metadata": {},
   "source": [
    "$NCR$ winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4aade73",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_ncr1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ce3aa7f",
   "metadata": {},
   "source": [
    "$sNCR$ winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47eff84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_ncr2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62379d87",
   "metadata": {},
   "source": [
    "Train model with optimal bandwidths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa08e334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init list to store models in\n",
    "m_opt = []\n",
    "\n",
    "# Iterate over targets\n",
    "for opt, target in [(opt_ncr1, 'ncr1'), (opt_ncr2, 'ncr2')]:\n",
    "\n",
    "    # Iterate over hours\n",
    "    for i, hour in enumerate(hours):\n",
    "\n",
    "        # Optimum bounds\n",
    "        lb = opt.iloc[i, 0].item()\n",
    "        ub = opt.iloc[i, 1].item()\n",
    "\n",
    "        # Mask\n",
    "        mask = donuts[hour] & df['r'].between(lb, ub)\n",
    "\n",
    "        # Fit models\n",
    "        m = sm.OLS.from_formula(\n",
    "            formula=f'{target}Post{hour} ~ treat + r + rTreat',\n",
    "            data=df[mask]\n",
    "        ).fit(cov_type='HC0')\n",
    "\n",
    "        # Append model to list\n",
    "        m_opt.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25b17db",
   "metadata": {},
   "source": [
    "Extract results from each optimized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b82d1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init list\n",
    "d = []\n",
    "\n",
    "# Extract results from each winning model\n",
    "for i in range(len(m_opt)):\n",
    "    d.append(\n",
    "        [\n",
    "            m_opt[i].params['treat'],\n",
    "            m_opt[i].bse['treat'],\n",
    "            m_opt[i].pvalues['treat'],\n",
    "            stars(\n",
    "                m_opt[i].pvalues['treat']\n",
    "            ),\n",
    "            m_opt[i].predict(\n",
    "                {'treat':0, 'r':0, 'rTreat':0}\n",
    "            ).item(),\n",
    "            m_opt[i].rsquared,\n",
    "            int(m_opt[i].nobs)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# Results to dataframe\n",
    "d = pd.DataFrame(data=d, columns=['T', 'se', 'pval', 'signif', 'mean', 'R2', 'nobs'])\n",
    "\n",
    "# View results\n",
    "d.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985e61a0",
   "metadata": {},
   "source": [
    "#### 4.2.3. Fake cutoffs\n",
    "\n",
    "Assume fake cutoffs $\\{-48, -36, -24, -12, 0, 12, 24, 36, 48\\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5b2596",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert targets to readable titles\n",
    "depvar = {'ncr1': 'NCR', 'ncr2': 'sNCR'}\n",
    "\n",
    "# Init list to store shifts in\n",
    "shifted = []\n",
    "\n",
    "# Iterate over targets\n",
    "for target in ['ncr1', 'ncr2']:\n",
    "\n",
    "    # Iterate over time windows\n",
    "    for h in hours:\n",
    "\n",
    "        # Iterate over shifts\n",
    "        for s in np.arange(-48, 48+1, 12):\n",
    "\n",
    "            # Copy data (after dropping videos with no comments)\n",
    "            d = df.loc[\n",
    "                df[f'commentsNumPost{h}'].gt(min_comments),\n",
    "                [f'{target}Post{h}', 'r']\n",
    "            ].copy()\n",
    "    \n",
    "            # Shift running variable and assign treatment\n",
    "            d['r'] = d['r'].add(s*60**2)\n",
    "            d['treat'] = np.where(d['r'] >= 0, 1, 0)\n",
    "\n",
    "            # Remove donut hole\n",
    "            d = d[d['r'].le(-h*60**2) | d['r'].ge(24*60**2)]\n",
    "\n",
    "            # Only continue if there's data on both sides of 0\n",
    "            if (d['r'].lt(0).sum() > 0) & (d['r'].gt(0).sum() > 0):\n",
    "\n",
    "                # Fit model\n",
    "                m = sm.OLS.from_formula(\n",
    "                    formula=f'{target}Post{h} ~ treat + r + I(r*treat)',\n",
    "                    data=d\n",
    "                ).fit(cov_type='HC0')\n",
    "\n",
    "                # Append results\n",
    "                shifted.append(\n",
    "                    [\n",
    "                        f'{depvar[target]} (h = {h})',\n",
    "                        s,\n",
    "                        m.params['treat'],\n",
    "                        m.bse['treat'],\n",
    "                        m.pvalues['treat'],\n",
    "                        stars(m.pvalues['treat'])\n",
    "                    ]\n",
    "                )\n",
    "            \n",
    "            # Prompt skipped cases\n",
    "            else:\n",
    "                print(f'Skipped {target}Post{h} with shift = {s}')\n",
    "\n",
    "# Results to dataframe\n",
    "shifted = pd.DataFrame(\n",
    "    data=shifted,\n",
    "    columns=['Case', 'Shift', 'LATE', 'SE', 'p-value', 'Significance']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618c618b",
   "metadata": {},
   "source": [
    "$NCR$ placebo results\n",
    "\n",
    "$h = 12$ was significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0faa874",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted[shifted['Case'].eq('NCR (h = 12)')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5024db",
   "metadata": {},
   "source": [
    "$NCR(h = 24)$ was not significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0faa874",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted[shifted['Case'].eq('NCR (h = 24)')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41947a21",
   "metadata": {},
   "source": [
    "$NCR(h = 36)$ was significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0faa874",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted[shifted['Case'].eq('NCR (h = 36)')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7fda85",
   "metadata": {},
   "source": [
    "$NCR(h = 48)$ was significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0faa874",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted[shifted['Case'].eq('NCR (h = 48)')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28814e13",
   "metadata": {},
   "source": [
    "$sNCR(h = 12)$ is significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f607cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted[shifted['Case'].eq('sNCR (h = 12)')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28814e13",
   "metadata": {},
   "source": [
    "$sNCR(h = 24)$ is significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f607cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted[shifted['Case'].eq('sNCR (h = 24)')]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33cb6b5",
   "metadata": {
    "id": "f33cb6b5"
   },
   "source": [
    "### 4.4. Visualizations\n",
    "Create dataframe with predictions from models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89626b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init data\n",
    "d = pd.DataFrame({'r':np.arange(-5*24*60**2, 5*24*60**2, 60**2)})\n",
    "\n",
    "# Assign treatment\n",
    "d['treat'] = np.where(d['r'].le(0), 0, 1)\n",
    "\n",
    "# Init index counter\n",
    "i = 0\n",
    "\n",
    "# Iterate over targets\n",
    "for target in ['ncr1', 'ncr2', 'pcr1', 'pcr2', 'rel1', 'rel2']:\n",
    "\n",
    "    # Iterate over Post%H windows\n",
    "    for h, post in zip(hours, windows):\n",
    "\n",
    "        # Select model\n",
    "        model = d1[i]\n",
    "\n",
    "        # Init empty list\n",
    "        preds = []\n",
    "\n",
    "        # Make predictions\n",
    "        for idx, vals in d.iterrows():\n",
    "            pred = model.predict({'r':vals['r'], 'treat':vals['treat']})\n",
    "            preds.append(pred.item())\n",
    "\n",
    "        # Add predictions to dataframe\n",
    "        d[f'{target}{post}'] = preds\n",
    "\n",
    "        # Add 1 to counter\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb961bd",
   "metadata": {},
   "source": [
    "Create plots for `ncr1` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819d2030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target name\n",
    "target = 'ncr1'\n",
    "\n",
    "# Init figure\n",
    "fig, axs = plt.subplots(nrows=3, ncols=2, sharex=True, sharey=True)\n",
    "fig.set_figheight(8)\n",
    "fig.set_figwidth(8)\n",
    "\n",
    "# Iterate over hours\n",
    "for i, h in enumerate(hours):\n",
    "\n",
    "    # Flatten axes\n",
    "    ax = axs.flatten()[i]\n",
    "\n",
    "    # Masks\n",
    "    pre = d['r'].le(-h*60**2)\n",
    "    pre_hat = d['r'].between(-h*60**2, 0)\n",
    "    post_hat = d['r'].between(60**2, 24*60**2)\n",
    "    post = d['r'].ge(24*60**2)\n",
    "\n",
    "    # Predicted lines\n",
    "    ax.plot(d.loc[pre, 'r'], d.loc[pre, f'{target}Post{h}'], color='C0')\n",
    "    ax.plot(d.loc[pre_hat, 'r'], d.loc[pre_hat, f'{target}Post{h}'], color='C1', ls='--')\n",
    "    ax.plot(d.loc[post_hat, 'r'], d.loc[post_hat, f'{target}Post{h}'], color='C1', ls='--')\n",
    "    ax.plot(d.loc[post, 'r'], d.loc[post, f'{target}Post{h}'], color='C0')\n",
    "\n",
    "    # Shaded regions\n",
    "    ax.axvspan(xmin=-h*60**2, xmax=0, color='C0', alpha=0.5)\n",
    "    ax.axvspan(xmin=0, xmax=24*60**2, color='gray', alpha=0.5)\n",
    "    \n",
    "    # Aesthetics\n",
    "    ax.set_title(f'First {h} hours', fontsize=10)\n",
    "    ax.set_xticks(np.linspace(-5*24*60**2, 5*24*60**2+1, 11))\n",
    "    ax.set_xticklabels(np.arange(-5, 5+1))\n",
    "    if i > 3:\n",
    "        ax.set_xlabel('Days since November 10')\n",
    "    if i % 2 == 0:\n",
    "        ax.set_ylabel('NCR')\n",
    "\n",
    "    # Get grouped means from targets\n",
    "    t = df[~df['r'].between(-h*60**2, 24*60**2)].copy()\n",
    "    t['bins'] = pd.qcut(t['r'], 35)\n",
    "    x = t.groupby('bins')[f'{target}Post{h}'].mean()\n",
    "    \n",
    "    # Plot bins from targets\n",
    "    ax.scatter(\n",
    "        [val.left for val in x.index.values],\n",
    "        x.values,\n",
    "        color='C4',\n",
    "        s=15\n",
    "    )\n",
    "\n",
    "# Set limits\n",
    "ax.set_xlim(-24*5*60**2, 24*5*60**2+1)\n",
    "ax.set_ylim(0, 0.8)\n",
    "\n",
    "# Save and show\n",
    "plt.savefig('../../fig/fig_ncr1.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81349734",
   "metadata": {},
   "source": [
    "Create plots for `ncr2` models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460a6cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target name\n",
    "target = 'ncr2'\n",
    "\n",
    "# Init figure\n",
    "fig, axs = plt.subplots(nrows=3, ncols=2, sharex=True, sharey=True)\n",
    "fig.set_figheight(8)\n",
    "fig.set_figwidth(8)\n",
    "\n",
    "# Iterate over hours\n",
    "for i, h in enumerate(hours):\n",
    "\n",
    "    # Flatten axes\n",
    "    ax = axs.flatten()[i]\n",
    "\n",
    "    # Masks\n",
    "    pre = d['r'].le(-h*60**2)\n",
    "    pre_hat = d['r'].between(-h*60**2, 0)\n",
    "    post_hat = d['r'].between(60**2, 24*60**2)\n",
    "    post = d['r'].ge(24*60**2)\n",
    "\n",
    "    # Predicted lines\n",
    "    ax.plot(d.loc[pre, 'r'], d.loc[pre, f'{target}Post{h}'], color='C0')\n",
    "    ax.plot(d.loc[pre_hat, 'r'], d.loc[pre_hat, f'{target}Post{h}'], color='C1', ls='--')\n",
    "    ax.plot(d.loc[post_hat, 'r'], d.loc[post_hat, f'{target}Post{h}'], color='C1', ls='--')\n",
    "    ax.plot(d.loc[post, 'r'], d.loc[post, f'{target}Post{h}'], color='C0')\n",
    "\n",
    "    # Shaded regions\n",
    "    ax.axvspan(xmin=-h*60**2, xmax=0, color='C0', alpha=0.5)\n",
    "    ax.axvspan(xmin=0, xmax=24*60**2, color='gray', alpha=0.5)\n",
    "    \n",
    "    # Aesthetics\n",
    "    ax.set_title(f'First {h} hours', fontsize=10)\n",
    "    ax.set_xticks(np.linspace(-5*24*60**2, 5*24*60**2+1, 11))\n",
    "    ax.set_xticklabels(np.arange(-5, 5+1))\n",
    "    if i > 3:\n",
    "        ax.set_xlabel('Days since November 10')\n",
    "    if i % 2 == 0:\n",
    "        ax.set_ylabel('sNCR')\n",
    "\n",
    "    # Get grouped means from targets\n",
    "    t = df[~df['r'].between(-h*60**2, 24*60**2)].copy()\n",
    "    t['bins'] = pd.qcut(t['r'], 35)\n",
    "    x = t.groupby('bins')[f'{target}Post{h}'].mean()\n",
    "    \n",
    "    # Plot bins from targets\n",
    "    ax.scatter(\n",
    "        [val.left for val in x.index.values],\n",
    "        x.values,\n",
    "        color='C4',\n",
    "        s=15\n",
    "    )\n",
    "\n",
    "# Set limits\n",
    "ax.set_xlim(-24*5*60**2, 24*5*60**2+1)\n",
    "ax.set_ylim(0, 0.8)\n",
    "\n",
    "# Save and show\n",
    "plt.savefig('../../fig/fig_ncr2.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad8397b",
   "metadata": {},
   "source": [
    "Create figure for example of fit ($h = 24$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b43154d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set fig dimensions\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "# Declare hours\n",
    "h = 24\n",
    "\n",
    "# Masks\n",
    "pre = d['r'].le(-h*60**2)\n",
    "pre_hat = d['r'].between(-h*60**2, 0)\n",
    "post_hat = d['r'].between(60**2, 24*60**2)\n",
    "post = d['r'].ge(24*60**2)\n",
    "\n",
    "# Model lines\n",
    "plt.plot(d.loc[pre, 'r'], d.loc[pre, f'{target}Post{h}'], color='C0')\n",
    "plt.plot(d.loc[pre_hat, 'r'], d.loc[pre_hat, f'{target}Post{h}'], color='C1', ls='--')\n",
    "plt.plot(d.loc[post_hat, 'r'], d.loc[post_hat, f'{target}Post{h}'], color='C1', ls='--')\n",
    "plt.plot(d.loc[post, 'r'], d.loc[post, f'{target}Post{h}'], color='C0')\n",
    "\n",
    "# Shaded regions\n",
    "plt.axvspan(xmin=-h*60**2, xmax=0, color='C0', alpha=0.5)\n",
    "plt.axvspan(xmin=0, xmax=24*60**2, color='gray', alpha=0.5)\n",
    "\n",
    "# Aesthetics\n",
    "plt.xticks(\n",
    "    np.linspace(-5*24*60**2, 5*24*60**2+1, 11),\n",
    "    labels=np.arange(-5, 5+1)\n",
    ")\n",
    "plt.xlabel('Days since November 10')\n",
    "plt.ylabel('NCR(h = 12)')\n",
    "\n",
    "# Get grouped means from targets\n",
    "t = df[~df['r'].between(-h*60**2, 24*60**2)].copy()\n",
    "t['bins'] = pd.qcut(t['r'], 50)\n",
    "x = t.groupby('bins')[f'{target}Post{h}'].mean()\n",
    "\n",
    "# Plot bins from targets\n",
    "plt.scatter(\n",
    "    [val.left for val in x.index.values],\n",
    "    x.values,\n",
    "    color='C4',\n",
    "    s=15\n",
    ")\n",
    "\n",
    "# Aesthetics\n",
    "plt.ylim(0.2, 0.8)\n",
    "plt.xlim(-5*h*60**2, 5*h*60**2+1)\n",
    "\n",
    "# Save and show\n",
    "plt.savefig('../../fig/fig_h24.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "01_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "95c0f0991ffcdb038fcf97c3f0d49464981cd58006e8af0cf678ddb2337346a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
