{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc3dd112",
   "metadata": {
    "id": "dc3dd112"
   },
   "source": [
    "# Analysis\n",
    "This notebook creates features from raw tables and visualizes the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19693b80",
   "metadata": {
    "id": "19693b80"
   },
   "source": [
    "## 1. Set environment\n",
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17591853",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17591853",
    "outputId": "e919d802-8ac8-465d-9f60-e555f75b91b7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import floor\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import statsmodels.api as sm\n",
    "from isodate import parse_duration\n",
    "from scipy.stats import ttest_ind\n",
    "from stargazer.stargazer import Stargazer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e10a6b",
   "metadata": {},
   "source": [
    "The following cell parses json files. Avoid running it again."
   ]
  },
  {
   "cell_type": "raw",
   "id": "aaacf8f1",
   "metadata": {},
   "source": [
    "# Imports for this cell\n",
    "import os\n",
    "import json\n",
    "\n",
    "# List of all files\n",
    "files = [file for file in os.listdir('../../dat/comments/') if '.json' in file]\n",
    "\n",
    "# Count all comments scraped\n",
    "allComments = 0\n",
    "for file in files:\n",
    "    cs = json.load(open(f'../../dat/comments/{file}'))\n",
    "    allComments += len(\n",
    "        cs.get(\n",
    "            file.replace('.json', '')\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Results\n",
    "print(f'Number of videos with at least one comment in first 12 hours:{len(files)}') # 1,846\n",
    "print(f'Number of comments scraped: {allComments}') # 1,197,454"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee4cd6e",
   "metadata": {},
   "source": [
    "Counts:\n",
    "- All videos\n",
    "    - 1,928\n",
    "- All videos with at least one comment in first 12 hours\n",
    "    - 1,846\n",
    "- All videos with at least one comment in English in first 12 hours\n",
    "    - 1,814\n",
    "- All videos with at least one comment in first 12 hours and excluding fuzzy window\n",
    "    - 1516\n",
    "- All videos with at least one comment in English in first 12 hours excluding fuzzy window\n",
    "    - 1504\n",
    "- All comments\n",
    "    - 1,197,454"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78b141c",
   "metadata": {
    "id": "b78b141c"
   },
   "source": [
    "Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178a85ed",
   "metadata": {
    "id": "178a85ed"
   },
   "outputs": [],
   "source": [
    "# Video details table\n",
    "d1 = pd.read_csv('../../dat/videoDetails.csv')\n",
    "\n",
    "# Classified comments\n",
    "# d2 = pd.read_csv('../../dat/videoFlags.csv') # Deprecated (no langid filter & no Nov-10 data)\n",
    "# d2 = pd.read_csv('../../dat/videoFlagsFuzzy.csv') # Deprecated (no langid filter)\n",
    "d2 = pd.read_csv('../../dat/videoFlagsFuzzyLangid.csv') # Current (has langid filter and Nov-10 data)\n",
    "\n",
    "# Create dataframe for analysis\n",
    "df = pd.merge(d1, d2, on='videoId', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc1abc6e",
   "metadata": {},
   "source": [
    "Create masks for each time window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705b88dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert publishedAt to timestamp\n",
    "df['publishedAt'] = pd.to_datetime(df['publishedAt'], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "# Start of policy rollout\n",
    "start = pd.Timestamp('2021-11-10 00:00:00')\n",
    "\n",
    "# Time windows\n",
    "hours = np.arange(12, 72+1, 12) # [12, 24, ..., 72]\n",
    "windows = [f'Post{h}' for h in hours] # [Post12, Post24, ..., Post72]\n",
    "\n",
    "# Init dict in which to store masks\n",
    "donuts = {}\n",
    "\n",
    "# Create masks for each time window\n",
    "# Iterate over time windows\n",
    "for h in hours:\n",
    "\n",
    "    # Set max time of upload before treatment\n",
    "    lim = start - pd.Timedelta(hours=h)\n",
    "\n",
    "    # Current mask\n",
    "    d = {\n",
    "        h:(\n",
    "            # Pre-treatment\n",
    "            df['publishedAt'].le(lim) |\n",
    "            # Post treatment\n",
    "            df['publishedAt'].ge('2021-11-11')\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Append masks to empty dict\n",
    "    donuts = {**donuts, **d}\n",
    "\n",
    "# Delete temporary dict\n",
    "del d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c563fb",
   "metadata": {
    "id": "75c563fb"
   },
   "source": [
    "## 2. Feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00aac58",
   "metadata": {
    "id": "f00aac58"
   },
   "source": [
    "Turn `definition` to dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74a69d2",
   "metadata": {
    "id": "b74a69d2"
   },
   "outputs": [],
   "source": [
    "df['definition'] = df['definition'].replace({'sd':'0','hd':'1'}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67536050",
   "metadata": {
    "id": "67536050"
   },
   "source": [
    "Create means from counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b37125f",
   "metadata": {
    "id": "2b37125f"
   },
   "outputs": [],
   "source": [
    "# Create per-video means\n",
    "for h in hours:\n",
    "\n",
    "    # NCRs\n",
    "    df[f'ncr1Post{h}'] = df[f'post{h}CommentsNeg1'] / df[f'post{h}CommentsNum'].replace(0, 1)\n",
    "    df[f'ncr2Post{h}'] = df[f'post{h}CommentsNeg2'] / df[f'post{h}CommentsNum'].replace(0, 1)\n",
    "    \n",
    "    # PCRs\n",
    "    df[f'pcr1Post{h}'] = df[f'post{h}CommentsPos1'] / df[f'post{h}CommentsNum'].replace(0, 1)\n",
    "    df[f'pcr2Post{h}'] = df[f'post{h}CommentsPos2'] / df[f'post{h}CommentsNum'].replace(0, 1)\n",
    "    \n",
    "    # Relative ratios\n",
    "    df[f'rel1Post{h}'] = np.where(\n",
    "        (df[f'post{h}CommentsNeg1'] > 0) & (df[f'post{h}CommentsPos1'] > 0),\n",
    "        df[f'post{h}CommentsNeg1'] / df[f'post{h}CommentsPos1'],\n",
    "        np.nan\n",
    "    )\n",
    "    df[f'rel2Post{h}'] = np.where(\n",
    "        (df[f'post{h}CommentsNeg2'] > 0) & (df[f'post{h}CommentsPos2'] > 0),\n",
    "        df[f'post{h}CommentsNeg2'] / df[f'post{h}CommentsPos2'],\n",
    "        np.nan\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a5c574",
   "metadata": {
    "id": "53a5c574"
   },
   "source": [
    "Analyze most important words in video titles to create dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3156b940",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "3156b940",
    "outputId": "e2ad3e11-0d95-4528-d39b-5d0771ecc114"
   },
   "outputs": [],
   "source": [
    "# All titles to single text\n",
    "text = ' '.join(df['title'].str.title().tolist())\n",
    "\n",
    "# Remove annoying strings\n",
    "for string in [\"'s\",\".\",\"-\"]:\n",
    "    text = text.replace(string, '')\n",
    "\n",
    "# All words to uppercase\n",
    "text = text.upper()\n",
    "# Stopwords\n",
    "stopwords = set(list(STOPWORDS) + ['SAY','SAYS','S'])\n",
    "\n",
    "# Plot wordcloud\n",
    "wordcloud = WordCloud(\n",
    "    background_color='white',\n",
    "    max_words=25,\n",
    "    stopwords=stopwords,\n",
    "    max_font_size=40, \n",
    "    scale=3,\n",
    "    random_state=42\n",
    ").generate(text)\n",
    "\n",
    "# Show wordcloud\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "plt.axis('off')\n",
    "plt.imshow(wordcloud)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65939766",
   "metadata": {},
   "source": [
    "Create dummy variables by topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f56b12",
   "metadata": {
    "id": "10f56b12"
   },
   "outputs": [],
   "source": [
    "# Title to lowercase\n",
    "df['title'] = df['title'].str.lower()\n",
    "\n",
    "# Dictionary of keywords\n",
    "topics = {\n",
    "    'biden':'biden',\n",
    "    'trump':'trump',\n",
    "    'president':'biden|trump',\n",
    "    'climate':'cop26|cop 26|climate',\n",
    "    'economy':'inflation|infrastructure|bill|economy',\n",
    "    'covid':'covid|covid19|covid-19|virus',\n",
    "    'violence':'kill|murder|assassins| die|dead|shoot|shot'\n",
    "}\n",
    "\n",
    "# Create Indicator variables\n",
    "for topic in topics.keys():\n",
    "    df[topic] = np.where(df['title'].str.contains(topics[topic]), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6b285d",
   "metadata": {
    "id": "2e6b285d"
   },
   "source": [
    "Video title sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83289431",
   "metadata": {
    "id": "83289431"
   },
   "outputs": [],
   "source": [
    "clf = SentimentIntensityAnalyzer()\n",
    "df['toneCom'] = df['title'].apply(lambda x: clf.polarity_scores(x)['compound'])\n",
    "df['tonePos'] = df['title'].apply(lambda x: clf.polarity_scores(x)['pos'])\n",
    "df['toneNeg'] = df['title'].apply(lambda x: clf.polarity_scores(x)['neg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba47247d",
   "metadata": {
    "id": "ba47247d"
   },
   "source": [
    "Translate `duration` to seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471d484e",
   "metadata": {
    "id": "471d484e"
   },
   "outputs": [],
   "source": [
    "# YT-duration format to seconds\n",
    "df['seconds'] = df['duration'].apply(lambda x: int(parse_duration(x).total_seconds()))\n",
    "\n",
    "# log(seconds)\n",
    "df['logSeconds'] = np.log(df['seconds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7712005",
   "metadata": {
    "id": "a7712005"
   },
   "source": [
    "Sort data by upload date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ad18a4",
   "metadata": {
    "id": "f4ad18a4"
   },
   "outputs": [],
   "source": [
    "df = df.sort_values('publishedAt', ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79daa2da",
   "metadata": {
    "id": "79daa2da"
   },
   "source": [
    "Treatment indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a317e68b",
   "metadata": {
    "id": "a317e68b"
   },
   "outputs": [],
   "source": [
    "df['treat'] = (df['publishedAt'] >= '2021-11-10').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71750b13",
   "metadata": {
    "id": "71750b13"
   },
   "source": [
    "Declare running variable $R_i$ and interaction term $R_i \\times T_i$\n",
    "- Before: Seconds until treatment (control was positive, treatment was negative)\n",
    "- Update: Seconds since treatment (control is negative, treatment is positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c4df5",
   "metadata": {
    "id": "6f3c4df5"
   },
   "outputs": [],
   "source": [
    "# Running variable\n",
    "df['r'] = (df['publishedAt'] - pd.Timestamp('2021-11-10')).dt.total_seconds()\n",
    "\n",
    "# Interaction\n",
    "df['rTreat'] = df['r'].multiply(df['treat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b283eaad",
   "metadata": {
    "id": "b283eaad"
   },
   "source": [
    "## 3. Descriptive Statistics\n",
    "### Counts\n",
    "Number of available videos as a function of $h$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9718a7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "a9718a7d",
    "outputId": "5c16e638-831e-45ac-af65-8a8a3c45e0b7"
   },
   "outputs": [],
   "source": [
    "# All post%HCommentsNum columns\n",
    "cols = [f'post{str(h)}CommentsNum' for h in hours]\n",
    "\n",
    "# Merge to get videoId & post{h}CommentsNum (full list of videos!)\n",
    "t = pd.merge(d1[['videoId','publishedAt']], d2[['videoId'] + cols], on='videoId', how='left')\n",
    "\n",
    "# publishedAt to Timestamp\n",
    "t['publishedAt'] = pd.to_datetime(t['publishedAt'], format='%Y-%m-%dT%H:%M:%SZ')\n",
    "\n",
    "# Create pre & post groups\n",
    "t['treat'] = t['publishedAt'] >= '2021-11-10'\n",
    "\n",
    "# Mask each column to avoid overlap with 2021-11-10\n",
    "for h, col in zip(hours, cols):\n",
    "    t[col] = t['publishedAt'].le(pd.Timestamp('2021-11-10') - pd.Timedelta(hours=h)) | t['publishedAt'].ge('2021-11-11')\n",
    "\n",
    "# Group by treatment and get counts\n",
    "t = t.groupby('treat').agg(dict(zip(cols, ['sum']*7))).transpose()\n",
    "\n",
    "# Total number of videos column\n",
    "t['total'] = t.sum(axis=1)\n",
    "\n",
    "# Format\n",
    "t.index = ['h = ' + str(h) for h in windows]\n",
    "t\n",
    "\n",
    "# To latex\n",
    "# print(\n",
    "#    t.to_latex(\n",
    "#         caption='Number of available videos before and after November 10, 2021 for different values of $h$',\n",
    "#         label='tab_dat_nobs'\n",
    "#     )\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df25858b",
   "metadata": {
    "id": "df25858b"
   },
   "source": [
    "### Balance tests\n",
    "\n",
    "Balance table using a linear stepwise design and excluding the donut hole for $h = 12$.\n",
    "\n",
    "$$X_i = \\gamma_0 + \\gamma_1 r_i + \\gamma_2 T_i + \\gamma_3 (r_i \\times T_i) + V_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82bd8c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "b82bd8c2",
    "outputId": "c6f5dd0b-864a-4ebf-8fbe-2449e36addbf"
   },
   "outputs": [],
   "source": [
    "# Mask to avoid overlap with November 10 (h = 12)\n",
    "mask = df['r'].le(-12*60**2) | df['r'].ge(24*60**2)\n",
    "print(f'{mask.sum()} videos used in balance test.')\n",
    "\n",
    "# Copy data\n",
    "d = df[mask].copy()\n",
    "\n",
    "# Create video length (minutes)\n",
    "d['durationMins'] = d['seconds'].div(60)\n",
    "\n",
    "# Order frequent-word variables by frequency\n",
    "X = list(topics.keys()) + ['definition','durationMins','tonePos','toneNeg','toneCom']\n",
    "\n",
    "# Regress each variable on r and treat\n",
    "data = []\n",
    "for x in X:\n",
    "    m = sm.OLS.from_formula(\n",
    "        data=d,\n",
    "        formula=f'{x} ~ r + treat + I(r*treat)',\n",
    "    ).fit(cov_type='HC0')\n",
    "    data.append((m.params['treat'], m.pvalues['treat']))\n",
    "\n",
    "# Summary table\n",
    "t = pd.DataFrame(data=data, index=X, columns=['Estimated Value','p-value'])\n",
    "t.index.rename('Covariate', inplace=True)\n",
    "t.reset_index(inplace=True)\n",
    "\n",
    "# Print exog that did not pass balance test\n",
    "print('Variables that did not pass: \\n', t.loc[t['p-value'].lt(0.1), 'Covariate'], sep='')\n",
    "\n",
    "# View\n",
    "t.round(3)\n",
    "\n",
    "# To latex\n",
    "# print(t.to_latex(caption='Regression discontinuities on observable characteristics',\n",
    "#                  label='tab_dat_balance', float_format='%.3f', index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d677e",
   "metadata": {
    "id": "4f5d677e"
   },
   "source": [
    "## 4. Regression Analysis\n",
    "\n",
    "Convenience functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368226f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stars function\n",
    "def stars(pval):\n",
    "    if pval <= 0.01:\n",
    "        return '***'\n",
    "    elif pval <= 0.05:\n",
    "        return '**'\n",
    "    elif pval <= 0.1:\n",
    "        return '*'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# Function to extract most relevant info from RDD\n",
    "def get_info(models, dep_vars, hours):\n",
    "\n",
    "    # Form dataframe\n",
    "    t =  pd.DataFrame(\n",
    "        {\n",
    "            # Targets\n",
    "            'y':np.repeat(dep_vars, len(hours)),\n",
    "            # Time windows\n",
    "            'h':list(hours)*len(dep_vars),\n",
    "            # Betas\n",
    "            'T':[models[i].params['treat'] for i in range(len(models))],\n",
    "            # Standard errors\n",
    "            'se':[models[i].bse['treat'] for i in range(len(models))],\n",
    "            # p-values\n",
    "            'pval':[models[i].pvalues['treat'] for i in range(len(models))],\n",
    "            # Significance\n",
    "            'signif':[stars(models[i].pvalues['treat']) for i in range(len(models))],\n",
    "            # Mean at r=0\n",
    "            'mean':[models[i].predict({'r':0, 'treat':0}).item() for i in range(len(models))],\n",
    "            # R2\n",
    "            'R2':[models[i].rsquared for i in range(len(models))],\n",
    "            # Number of observations\n",
    "            'nobs':[int(models[i].nobs) for i in range(len(models))]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Reindex table\n",
    "    return t.set_index(['y', 'h'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9926ce5e",
   "metadata": {},
   "source": [
    "### Fit models without donut hole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ccb88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum number of comments\n",
    "minComments = 0\n",
    "\n",
    "# Empty lists to store results in\n",
    "d0 = []\n",
    "\n",
    "# Iterate over targets\n",
    "for target in ['ncr1', 'ncr2', 'pcr1', 'pcr2', 'rel1', 'rel2']:\n",
    "\n",
    "    # Iterate over Post%H windows\n",
    "    for h, post in zip(hours, windows):\n",
    "\n",
    "        # Mask (Post%HCommentsNum > 0)\n",
    "        mask = df[f'{post.lower()}CommentsNum'] > 0\n",
    "\n",
    "        # Formula for first-degree polynomial\n",
    "        p1 = f'{target}{post} ~ treat + r + I(r*treat)'\n",
    "\n",
    "        # Fit models\n",
    "        m1 = sm.OLS.from_formula(formula=p1, data=df[mask]).fit(cov_type='HC0')\n",
    "\n",
    "        # Append to list\n",
    "        d0.append(m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d469c561",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_info(d0, ['ncr1', 'ncr2', 'pcr1', 'pcr2', 'rel1', 'rel2'], hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9769ad5",
   "metadata": {},
   "source": [
    "### Fit models with donut\n",
    "`d1:` $Y_i = \\beta_0 + \\beta_1 r_i + \\beta_2 T_i + \\beta_3 (T_i \\times r_i) + U_i$\n",
    "\n",
    "`d2:` $Y_i = \\beta_0 + \\beta_1 r_i + \\beta_2 r_i^2 + \\beta_3 T_i + \\beta_4 (T_i \\times r_i) + \\beta_5 (T_i \\times r_i)^2 + V_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b351ad",
   "metadata": {
    "id": "b2b351ad",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Empty lists to store results in\n",
    "d1, d2 = [], []\n",
    "\n",
    "# Iterate over targets\n",
    "for target in ['ncr1', 'ncr2', 'pcr1', 'pcr2', 'rel1', 'rel2']:\n",
    "\n",
    "    # Iterate over Post%H windows\n",
    "    for h, post in zip(hours, windows):\n",
    "\n",
    "        # Masks for `rel1` & `rel2`\n",
    "        if 'rel' in target:\n",
    "            mask = donuts[h] & (df[f'{target}{post}'].notna()) & (df[f'{post.lower()}CommentsNum'] > minComments)\n",
    "        \n",
    "        # Masks for `ncr` and `pcr`\n",
    "        else:\n",
    "            mask = donuts[h] & (df[f'{post.lower()}CommentsNum'] > minComments)\n",
    "\n",
    "        # Formula for first-degree polynomial\n",
    "        p1 = f'{target}{post} ~ treat + r + I(r*treat)'\n",
    "        \n",
    "        # Formula for second-degree polynomial\n",
    "        p2 = f'{target}{post} ~ treat + r + I(r**2) + I(r*treat) + I((r*treat)**2)'\n",
    "\n",
    "        # Fit models\n",
    "        m1 = sm.OLS.from_formula(formula=p1, data=df[mask]).fit(cov_type='HC0')\n",
    "        m2 = sm.OLS.from_formula(formula=p2, data=df[mask]).fit(cov_type='HC0')\n",
    "\n",
    "        # Append to list\n",
    "        d1.append(m1)\n",
    "        d2.append(m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a65066",
   "metadata": {},
   "source": [
    "Summary tables for linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23153466",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1Res = get_info(d1, ['ncr1', 'ncr2', 'pcr1', 'pcr2', 'rel1', 'rel2'], hours)\n",
    "d2Res = get_info(d2, ['ncr1', 'ncr2', 'pcr1', 'pcr2', 'rel1', 'rel2'], hours)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fbe456b",
   "metadata": {},
   "source": [
    "View linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b83524",
   "metadata": {},
   "outputs": [],
   "source": [
    "d1Res.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cb054ec",
   "metadata": {},
   "source": [
    "View quadratic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3960da92",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2Res.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33cb6b5",
   "metadata": {
    "id": "f33cb6b5"
   },
   "source": [
    "### 4.4. Visualizations\n",
    "Linear and quadratic RDD for $NCR(12)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d455003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linrear and quadratic models\n",
    "l, q = d1[0], d2[0]\n",
    "\n",
    "# Data and predictions for lines\n",
    "t = pd.DataFrame({'r':df.loc[mask, 'r'],\n",
    "                  'l':d1[0].fittedvalues.values,\n",
    "                  'q':d2[0].fittedvalues.values})\n",
    "t['treat'] = (t['r'] > 0).astype(int)\n",
    "\n",
    "# Data for scatter\n",
    "bin_length = 4\n",
    "s = df.loc[mask, ['ncr1Post12','r']].copy()\n",
    "s['bin'] = (s['r'].div(60 * 60) / bin_length).apply(lambda x: floor(x))\n",
    "s = s.groupby('bin')['ncr1Post12'].mean().reset_index(name='mean')\n",
    "s['bin'] = s['bin'].multiply(bin_length * 60 * 60)\n",
    "\n",
    "# Initialize figure\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(14)\n",
    "\n",
    "# Plot model on each axis\n",
    "for i, ax in enumerate(axs):\n",
    "    # Plot linear model\n",
    "    if i == 0:\n",
    "        series = 'l'\n",
    "    else:\n",
    "        series = 'q'\n",
    "    # Lines\n",
    "    ax.plot(t.loc[t['treat'].eq(0), 'r'], t.loc[t['treat'].eq(0), series], color='C1')\n",
    "    ax.plot(t.loc[t['treat'].eq(1), 'r'], t.loc[t['treat'].eq(1), series], color='C1')\n",
    "    # Scatter\n",
    "    ax.scatter(s['bin'], s['mean'], color='C0', alpha=0.5)\n",
    "    # Shaded regions\n",
    "    ax.axvspan(xmin=0, xmax=24*60*60, color='gray', alpha=0.3)\n",
    "    ax.axvspan(xmin=-12*60*60, xmax=0, color='C0', alpha=0.3)\n",
    "    # X&Y axes\n",
    "    ax.set_xticks(np.arange(-5*24*60*60, 6*24*60*60+1, 24 * 60 * 60))\n",
    "    ax.set_xticklabels(np.arange(-5*24, 6*24+1, 24), rotation=45)\n",
    "    ax.set_xlim(-5*24*60*60, 6*24*60*60)\n",
    "    ax.set_ylim(0, 0.7)\n",
    "    # Labels\n",
    "    title = {'l':'First-degree polynomial','q':'Second-degree polynomial'}\n",
    "    ax.set_title(f'{title[series]}')\n",
    "    ax.set_xlabel('Hours until policy')\n",
    "    ax.set_ylabel('Negative Comment Ration (h=12)')\n",
    "    ax.grid(which='major', axis='x')\n",
    "# Save and show\n",
    "if 'google.colab' not in sys.modules:\n",
    "    plt.savefig('../../fig/fig_d1d2.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c708f391",
   "metadata": {
    "id": "c708f391"
   },
   "source": [
    "All linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2885f76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig, axs = plt.subplots(nrows=6, ncols=2)\n",
    "fig.set_figheight(20)\n",
    "fig.set_figwidth(14)\n",
    "\n",
    "# Plot within each axis\n",
    "for i, ax_row in enumerate(axs):\n",
    "    # Left-right plots\n",
    "    for j, ax in enumerate(ax_row):\n",
    "        if j == 0:\n",
    "            outcome = f'ncr1{windows[i]}'\n",
    "            dotColor = 'blue'\n",
    "            ax.set_ylabel(f'NCR(h = {hours[i]})')\n",
    "            model = d1[i]\n",
    "        else:\n",
    "            outcome = f'ncr2{windows[i]}'\n",
    "            dotColor = 'lightblue'\n",
    "            ax.set_ylabel(f'sNCR(h = {hours[i]})')\n",
    "            model = d1[6+i]\n",
    "        # Masks\n",
    "        mask = df['post12CommentsNum'].gt(0) & df[outcome].notna()\n",
    "        # Line plots\n",
    "        t = df.loc[mask, ['treat','r']].assign(pred = model.fittedvalues)\n",
    "        ax.plot(t.loc[t['treat'].eq(0), 'r'], t.loc[t['treat'].eq(0), 'pred'], color='C1')\n",
    "        ax.plot(t.loc[t['treat'].eq(1), 'r'], t.loc[t['treat'].eq(1), 'pred'], color='C1')\n",
    "        # Scatter plots\n",
    "        s = df[mask].copy()\n",
    "        s['bin'] = (s['r'].div(4*60*60)).apply(lambda x: floor(x))\n",
    "        s = s.groupby('bin')[outcome].mean().reset_index(name='mean')\n",
    "        s['bin'] = s['bin'] * (4*60*60)\n",
    "        ax.scatter(x=s['bin'], y=s['mean'], color='C0', alpha=0.5)\n",
    "        # Shades\n",
    "        ax.axvspan(xmin=0, xmax=24*60*60, color='gray', alpha=0.3)\n",
    "        ax.axvspan(xmin=-hours[i]*60*60, xmax=0, color='C0', alpha=0.3)\n",
    "        # Axes\n",
    "        ax.set_ylim(0, 0.7)\n",
    "        ax.set_xticks(np.arange(-5*24*60*60, 6*24*60*60+1, 24*60*60))\n",
    "        ax.set_xticklabels(np.arange(-5*24, 6*24+1, 24))\n",
    "        ax.grid(which='major', axis='x')\n",
    "        if i == 0:\n",
    "            ax.set_title({0:'Negative Comment Ratio',1:'Somewhat Negative Comment Ratio'}[j])\n",
    "        if i == 5:\n",
    "            ax.set_xlabel('Hours until policy')\n",
    "# Show & save\n",
    "if 'google.colab' not in sys.modules:\n",
    "    plt.savefig('../../fig/fig_res_d1all.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de1037d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6de1037d",
    "outputId": "09c5ff88-652f-4e1f-9f48-ebf0723c76e9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig, axs = plt.subplots(nrows=6, ncols=2)\n",
    "fig.set_figheight(20)\n",
    "fig.set_figwidth(14)\n",
    "\n",
    "# Plot within each axis\n",
    "for i, ax_row in enumerate(axs):\n",
    "    # Left-right plots\n",
    "    for j, ax in enumerate(ax_row):\n",
    "        if j == 0:\n",
    "            outcome = f'ncr1{windows[i]}'\n",
    "            dotColor = 'blue'\n",
    "            ax.set_ylabel(f'NCR(h = {hours[i]})')\n",
    "            model = d2[i]\n",
    "        else:\n",
    "            outcome = f'ncr2{windows[i]}'\n",
    "            dotColor = 'lightblue'\n",
    "            ax.set_ylabel(f'sNCR(h = {hours[i]})')\n",
    "            model = d2[6+i]\n",
    "        # Masks\n",
    "        mask = df['post12CommentsNum'].gt(0) & df[outcome].notna()\n",
    "        # Line plots\n",
    "        t = df.loc[mask, ['treat','r']].assign(pred = model.fittedvalues)\n",
    "        ax.plot(t.loc[t['treat'].eq(0), 'r'], t.loc[t['treat'].eq(0), 'pred'], color='C1')\n",
    "        ax.plot(t.loc[t['treat'].eq(1), 'r'], t.loc[t['treat'].eq(1), 'pred'], color='C1')\n",
    "        # Scatter plots\n",
    "        s = df[mask].copy()\n",
    "        s['bin'] = (s['r'].div(4*60*60)).apply(lambda x: floor(x))\n",
    "        s = s.groupby('bin')[outcome].mean().reset_index(name='mean')\n",
    "        s['bin'] = s['bin'] * (4*60*60)\n",
    "        ax.scatter(x=s['bin'], y=s['mean'], color='C0', alpha=0.5)\n",
    "        # Shades\n",
    "        ax.axvspan(xmin=0, xmax=24*60*60, color='gray', alpha=0.3)\n",
    "        ax.axvspan(xmin=-hours[i]*60*60, xmax=0, color='C0', alpha=0.3)\n",
    "        # Axes\n",
    "        ax.set_ylim(0, 0.7)\n",
    "        ax.set_xticks(np.arange(-5*24*60*60, 6*24*60*60+1, 24*60*60))\n",
    "        ax.set_xticklabels(np.arange(-5*24, 6*24+1, 24))\n",
    "        ax.grid(which='major', axis='x')\n",
    "        if i == 0:\n",
    "            ax.set_title({0:'Negative Comment Ratio',1:'Somewhat Negative Comment Ratio'}[j])\n",
    "        if i == 5:\n",
    "            ax.set_xlabel('Hours until policy')\n",
    "# Show & save\n",
    "if 'google.colab' not in sys.modules:\n",
    "    plt.savefig('../../fig/fig_res_d2all.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc4bffd",
   "metadata": {},
   "source": [
    "Comparing linear to quadratic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391592e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goodness of fit\n",
    "t = pd.DataFrame(\n",
    "    {\n",
    "        'd1R2a':[m.rsquared_adj for m in d1], 'd2R2a':[m.rsquared_adj for m in d2],\n",
    "        'd1bic':[m.bic for m in d1], 'd2bic':[m.bic for m in d2],\n",
    "        'd1aic':[m.aic for m in d1], 'd2aic':[m.aic for m in d2],\n",
    "    }\n",
    ")\n",
    "\n",
    "t.round(4)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "01_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "95c0f0991ffcdb038fcf97c3f0d49464981cd58006e8af0cf678ddb2337346a8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
