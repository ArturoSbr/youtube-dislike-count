{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc3dd112",
   "metadata": {
    "id": "dc3dd112"
   },
   "source": [
    "# Analysis\n",
    "This notebook creates features from raw tables and visualizes the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19693b80",
   "metadata": {
    "id": "19693b80"
   },
   "source": [
    "## 1. Set environment\n",
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17591853",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17591853",
    "outputId": "e919d802-8ac8-465d-9f60-e555f75b91b7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import floor\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "import statsmodels.api as sm\n",
    "from isodate import parse_duration\n",
    "from scipy.stats import ttest_ind\n",
    "from stargazer.stargazer import Stargazer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32e10a6b",
   "metadata": {},
   "source": [
    "The following cell parses json files. Avoid running it again."
   ]
  },
  {
   "cell_type": "raw",
   "id": "aaacf8f1",
   "metadata": {},
   "source": [
    "# Imports for this cell\n",
    "import os\n",
    "import json\n",
    "\n",
    "# List of all files\n",
    "files = [file for file in os.listdir('../../dat/comments/') if '.json' in file]\n",
    "\n",
    "# Count all comments scraped\n",
    "allComments = 0\n",
    "for file in files:\n",
    "    cs = json.load(open(f'../../dat/comments/{file}'))\n",
    "    allComments += len(\n",
    "        cs.get(\n",
    "            file.replace('.json', '')\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Results\n",
    "print(f'Number of videos with at least one comment in first 12 hours:{len(files)}') # 1,846\n",
    "print(f'Number of comments scraped: {allComments}') # 1,197,454"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee4cd6e",
   "metadata": {},
   "source": [
    "Counts:\n",
    "- All videos\n",
    "    - 1,928\n",
    "- All videos with at least one comment in first 12 hours\n",
    "    - 1,846\n",
    "- All videos with at least one comment in English in first 12 hours\n",
    "    - ?\n",
    "- All videos with at least one comment in first 12 hours and excluding fuzzy window\n",
    "    - 1533\n",
    "- All videos with at least one comment in English in first 12 hours excluding fuzzy window\n",
    "    - ?\n",
    "- All comments\n",
    "    - 1,197,454"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78b141c",
   "metadata": {
    "id": "b78b141c"
   },
   "source": [
    "Read datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ceeeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1 = pd.read_csv('../../dat/videoFlags.csv')\n",
    "v2 = pd.read_csv('../../dat/videoFlagsFuzzy.csv')\n",
    "v3 = pd.read_csv('../../dat/videoFlagsFuzzyLangid.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81133a3d",
   "metadata": {},
   "source": [
    "In theory, there should be up to 198 new videos that were previously excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8e04eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Theoretical delta:', d1['publishedAt'].str[:10].eq('2021-11-10').sum())\n",
    "\n",
    "print('Factual delta:', len(v2) - len(v1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bf304b0",
   "metadata": {},
   "source": [
    "What dates are these new videos coming from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1379e470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add publishedAt to v2\n",
    "d = pd.merge(d1, v2['videoId'], on='videoId')\n",
    "\n",
    "# Check lengths\n",
    "len(d) == len(v2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6783ed39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Videos in v2 but not in v1\n",
    "d = d[~d['videoId'].isin(v1['videoId'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b50728",
   "metadata": {},
   "outputs": [],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5477617f",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['publishedAt'].str[:10].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178a85ed",
   "metadata": {
    "id": "178a85ed"
   },
   "outputs": [],
   "source": [
    "d1 = pd.read_csv('../../dat/videoDetails.csv')\n",
    "d2 = pd.read_csv('../../dat/videoFlags.csv')\n",
    "df = pd.merge(d1, d2, on='videoId', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e696b68",
   "metadata": {},
   "source": [
    "Data summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9639b7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "nvids = d2['videoId'].nunique()\n",
    "ncoms = round(df['post12CommentsNum'].sum(), -5)\n",
    "\n",
    "print(f'Scraped {int(ncoms)} from {nvids} Political videos.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c563fb",
   "metadata": {
    "id": "75c563fb"
   },
   "source": [
    "## 2. Feature creation\n",
    "Add constant term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743c9bef",
   "metadata": {
    "id": "743c9bef"
   },
   "outputs": [],
   "source": [
    "df['const'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ff59f3",
   "metadata": {
    "id": "e9ff59f3"
   },
   "source": [
    "Convert `publishedAt` to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c66655f",
   "metadata": {
    "id": "0c66655f"
   },
   "outputs": [],
   "source": [
    "df['publishedAt'] = pd.to_datetime(df['publishedAt'], format='%Y-%m-%dT%H:%M:%SZ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00aac58",
   "metadata": {
    "id": "f00aac58"
   },
   "source": [
    "Turn `definition` to dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74a69d2",
   "metadata": {
    "id": "b74a69d2"
   },
   "outputs": [],
   "source": [
    "df['definition'] = df['definition'].replace({'sd':'0','hd':'1'}).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67536050",
   "metadata": {
    "id": "67536050"
   },
   "source": [
    "Create targets from counters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b37125f",
   "metadata": {
    "id": "2b37125f"
   },
   "outputs": [],
   "source": [
    "# Hours (12, 24, 36, ...)\n",
    "hours = list(np.arange(12, 72+1, 12))\n",
    "\n",
    "# NCR and sNCR\n",
    "for h in hours:\n",
    "    df[f'ncr1Post{h}'] = df[f'post{h}CommentsNeg1'] / df[f'post{h}CommentsNum'].replace(0, 0.1)\n",
    "    df[f'ncr2Post{h}'] = df[f'post{h}CommentsNeg2'] / df[f'post{h}CommentsNum'].replace(0, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a5c574",
   "metadata": {
    "id": "53a5c574"
   },
   "source": [
    "Analyze most important words in video titles to create dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3156b940",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 366
    },
    "id": "3156b940",
    "outputId": "e2ad3e11-0d95-4528-d39b-5d0771ecc114"
   },
   "outputs": [],
   "source": [
    "# All titles to single text\n",
    "text = ' '.join(df['title'].str.title().tolist())\n",
    "\n",
    "# Remove annoying strings\n",
    "for string in [\"'s\",\".\",\"-\"]:\n",
    "    text = text.replace(string, '')\n",
    "\n",
    "# All words to uppercase\n",
    "text = text.upper()\n",
    "# Stopwords\n",
    "stopwords = set(list(STOPWORDS) + ['SAY','SAYS','S'])\n",
    "\n",
    "# Plot wordcloud\n",
    "wordcloud = WordCloud(\n",
    "    background_color='white',\n",
    "    max_words=25,\n",
    "    stopwords=stopwords,\n",
    "    max_font_size=40, \n",
    "    scale=3,\n",
    "    random_state=42\n",
    ").generate(text)\n",
    "\n",
    "# Show wordcloud\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "plt.axis('off')\n",
    "plt.imshow(wordcloud)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65939766",
   "metadata": {},
   "source": [
    "Create dummy variables by topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f56b12",
   "metadata": {
    "id": "10f56b12"
   },
   "outputs": [],
   "source": [
    "# Title to lowercase\n",
    "df['title'] = df['title'].str.lower()\n",
    "\n",
    "# Dictionary of keywords\n",
    "topics = {\n",
    "    'president':'biden|trump',\n",
    "    'climate':'cop26|cop 26|climate',\n",
    "    'economy':'inflation|infrastructure|bill|economy',\n",
    "    'covid':'covid|covid19|covid-19|virus',\n",
    "    'violence':'kill|murder|assassins| die|dead|shoot|shot'\n",
    "}\n",
    "\n",
    "# Create Indicator variables\n",
    "for topic in topics.keys():\n",
    "    df[topic] = np.where(df['title'].str.contains(topics[topic]), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6b285d",
   "metadata": {
    "id": "2e6b285d"
   },
   "source": [
    "Video title sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83289431",
   "metadata": {
    "id": "83289431"
   },
   "outputs": [],
   "source": [
    "clf = SentimentIntensityAnalyzer()\n",
    "df['toneCom'] = df['title'].apply(lambda x: clf.polarity_scores(x)['compound'])\n",
    "df['tonePos'] = df['title'].apply(lambda x: clf.polarity_scores(x)['pos'])\n",
    "df['toneNeg'] = df['title'].apply(lambda x: clf.polarity_scores(x)['neg'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba47247d",
   "metadata": {
    "id": "ba47247d"
   },
   "source": [
    "Translate `duration` to seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471d484e",
   "metadata": {
    "id": "471d484e"
   },
   "outputs": [],
   "source": [
    "# YT-duration format to seconds\n",
    "df['seconds'] = df['duration'].apply(lambda x: int(parse_duration(x).total_seconds()))\n",
    "\n",
    "# log(seconds)\n",
    "df['logSeconds'] = np.log(df['seconds'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7712005",
   "metadata": {
    "id": "a7712005"
   },
   "source": [
    "Sort data by upload date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ad18a4",
   "metadata": {
    "id": "f4ad18a4"
   },
   "outputs": [],
   "source": [
    "df = df.sort_values('publishedAt', ascending=True).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79daa2da",
   "metadata": {
    "id": "79daa2da"
   },
   "source": [
    "Treatment indicator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a317e68b",
   "metadata": {
    "id": "a317e68b"
   },
   "outputs": [],
   "source": [
    "df['treat'] = (df['publishedAt'] > '2021-11-10').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71750b13",
   "metadata": {
    "id": "71750b13"
   },
   "source": [
    "Declare running variable $R_i$ and interaction term $R_i \\times T_i$\n",
    "- Before: Seconds until treatment (control was positive, treatment was negative)\n",
    "- Update: Seconds since treatment (control is negative, treatment is positive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3c4df5",
   "metadata": {
    "id": "6f3c4df5"
   },
   "outputs": [],
   "source": [
    "# Running variable\n",
    "df['r'] = (df['publishedAt'] - pd.Timestamp('2021-11-10')).dt.total_seconds()\n",
    "\n",
    "# Interaction\n",
    "df['rTreat'] = df['r'].multiply(df['treat'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b283eaad",
   "metadata": {
    "id": "b283eaad"
   },
   "source": [
    "## 3. Balance tests\n",
    "List of targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30c905d",
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = [f'Post{h}' for h in hours]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8246963",
   "metadata": {
    "id": "d8246963"
   },
   "source": [
    "### 3.1. Descriptive statistics\n",
    "Number of available videos as a function of $h$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9718a7d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "a9718a7d",
    "outputId": "5c16e638-831e-45ac-af65-8a8a3c45e0b7"
   },
   "outputs": [],
   "source": [
    "# post{h}CommentsNum\n",
    "cols = [f'post{str(h)}CommentsNum' for h in hours]\n",
    "\n",
    "# Merge to get videoId & post{h}CommentsNum\n",
    "t = pd.merge(d1[['videoId','publishedAt']], d2[['videoId'] + cols], on='videoId', how='left')\n",
    "\n",
    "# Create C&T groups\n",
    "t['treat'] = (t['publishedAt'] > '2021-11-10').astype(int)\n",
    "\n",
    "# Count available videos per window\n",
    "t[cols] = t[cols].notna().astype(int)\n",
    "\n",
    "# Group by\n",
    "t = t.groupby('treat').agg({**{'videoId':'size'}, **dict(zip(cols,['sum']*6))}).transpose()\n",
    "\n",
    "# Format\n",
    "t.index = ['Total videos'] + ['h = ' + str(i*12) for i in range(1,7)]\n",
    "t\n",
    "\n",
    "# To latex\n",
    "# print(t.to_latex(caption='Number of available videos for different values of $h$',\n",
    "#                  label='tab_dat_nobs'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df25858b",
   "metadata": {
    "id": "df25858b"
   },
   "source": [
    "### 3.2. Balance\n",
    "\n",
    "Balance table for videos closest to the cutoff: $R_{hours} \\in [-36,-12] \\cup [24,36]$\n",
    "\n",
    "1. Difference in means for binary covariates\n",
    "1. RDD for continuous covariates\n",
    "\n",
    "$$X_i = \\gamma_0 + \\gamma_1 r_i + \\gamma_2 T_i + \\gamma_3 r_i T_i + V_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82bd8c2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 480
    },
    "id": "b82bd8c2",
    "outputId": "c6f5dd0b-864a-4ebf-8fbe-2449e36addbf"
   },
   "outputs": [],
   "source": [
    "# Bandwidth\n",
    "mask = df['r'].between(-36*60*60, -12*60*60) | df['r'].between(24*60*60, 48*60*60)\n",
    "print(f'{mask.sum()} videos used in balance test.')\n",
    "d = df[mask].copy()\n",
    "\n",
    "d['durationMins'] = d['seconds'].div(60)\n",
    "\n",
    "# Order frequent-word variables by frequency\n",
    "X = list(topics.keys()) + ['definition','durationMins','tonePos','toneNeg','toneCom']\n",
    "\n",
    "# Regress each variable on r and treat\n",
    "data = []\n",
    "for x in X:\n",
    "    m = sm.OLS(endog=d[x], exog=d[['const','r','treat','rTreat']]).fit()\n",
    "    data.append((m.params['treat'], m.pvalues['treat']))\n",
    "\n",
    "# Summary table\n",
    "t = pd.DataFrame(data=data, index=X, columns=['Estimated Value','p-value'])\n",
    "t.index.rename('Covariate', inplace=True)\n",
    "t.reset_index(inplace=True)\n",
    "t.round(3)\n",
    "\n",
    "# To latex\n",
    "# print(t.to_latex(caption='Regression discontinuities on observable characteristics',\n",
    "#                  label='tab_dat_balance', float_format='%.3f', index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5d677e",
   "metadata": {
    "id": "4f5d677e"
   },
   "source": [
    "## 4. Regression Analysis\n",
    "Fit all polynomial models with $d \\in \\{1, 2\\}$.\n",
    "\n",
    "### 4.1. First-degree\n",
    "$Y_i = \\beta_0 + \\beta_1 r_i + \\beta_2 T_i + \\beta_3 T_i \\times r_i + \\gamma X_i + U_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b351ad",
   "metadata": {
    "id": "b2b351ad",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Minumum number of comments\n",
    "mask = df['post12CommentsNum'] > 0\n",
    "\n",
    "# Fit all models\n",
    "d1 = []\n",
    "for target in ['ncr1','ncr2']:\n",
    "    for window in windows:\n",
    "        formula = f'{target}{window} ~ treat + r + I(r * treat)'\n",
    "        m = sm.OLS.from_formula(formula=formula, data=df[mask]).fit(cov_type='HC0')\n",
    "        d1.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a65066",
   "metadata": {},
   "source": [
    "$NCR(h)$ summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91021442",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "91021442",
    "outputId": "1d187b8a-debc-4026-c819-e1c5abd8c335",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Summaries\n",
    "ncr1d1 = Stargazer(d1[:6])\n",
    "ncr1d1.dependent_variable_name('Dependent Variable: Negative Comment Ratio')\n",
    "ncr1d1.custom_columns([f'h = {h}' for h in hours], [1]*6)\n",
    "ncr1d1.covariate_order(['treat','r','I(r * treat)','Intercept'])#,'toneNeg'])\n",
    "ncr1d1.rename_covariates({'I(r * treat)':'RxT','r':'R','treat':'T'})#,'toneNeg':'Negative tone'})\n",
    "ncr1d1.show_degrees_of_freedom(False)\n",
    "ncr1d1.add_custom_notes(['Robust standard errors (HC0)'])\n",
    "ncr1d1.show_model_numbers(False)\n",
    "ncr1d1.title('Estimated effects on Negative Comment Ratio (first-degree polynomial)')\n",
    "ncr1d1\n",
    "\n",
    "# Latex output\n",
    "# print(ncr1d1.render_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d5357c",
   "metadata": {
    "id": "a7d5357c"
   },
   "source": [
    "$sNCR(h)$ summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47cc774",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "a47cc774",
    "outputId": "99a754e6-711b-406f-e2bf-6abb3caa26d0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Model summaries\n",
    "ncr2d2 = Stargazer(d1[6:])\n",
    "ncr2d2.dependent_variable_name('Dependent Variable: Somewhat Negative Comment Ratio')\n",
    "ncr2d2.custom_columns([f'h = {h}' for h in hours], [1]*6)\n",
    "ncr2d2.covariate_order(['treat','r','I(r * treat)','Intercept'])#,'toneNeg'])\n",
    "ncr2d2.rename_covariates({'I(r * treat)':'RxT','r':'R','treat':'T'})#,'toneNeg':'Negative tone'})\n",
    "ncr2d2.show_degrees_of_freedom(False)\n",
    "ncr2d2.add_custom_notes(['Robust standard errors (HC0)'])\n",
    "ncr2d2.show_model_numbers(False)\n",
    "ncr2d2.title('Estimated effects on Somewhat Negative Comment Ratio (first-degree polynomial)')\n",
    "ncr2d2\n",
    "\n",
    "# Latex output\n",
    "# print(ncr2d2.render_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb1e9d8",
   "metadata": {},
   "source": [
    "### 4.2. Second-degree\n",
    "$$Y_i = \\beta_0 + \\beta_1 T_i + \\beta_2 R_i + \\beta_3 R_i^2 + \\beta_4 (T_i \\times R_i) + \\beta_5 (T_i \\times R_i^2) + \\gamma X_i + U_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df1ce20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minumum number of comments\n",
    "mask = df['post12CommentsNum'] > 0\n",
    "\n",
    "# Fit all models\n",
    "d2 = []\n",
    "for target in ['ncr1','ncr2']:\n",
    "    for window in windows:\n",
    "        formula = f'{target}{window} ~ treat + r + I(r**2) + I(treat * r) + I(treat * (r**2))'\n",
    "        m = sm.OLS.from_formula(formula=formula, data=df[mask]).fit(cov_type='HC0')\n",
    "        d2.append(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2da3694d",
   "metadata": {},
   "source": [
    "$NCR(h)$ summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ae25e2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "91021442",
    "outputId": "1d187b8a-debc-4026-c819-e1c5abd8c335",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Summaries\n",
    "ncr1d2 = Stargazer(d2[:6])\n",
    "ncr1d2.dependent_variable_name('Dependent Variable: Negative Comment Ratio')\n",
    "ncr1d2.custom_columns([f'h = {h}' for h in hours], [1]*6)\n",
    "ncr1d2.covariate_order(['treat','r','I(r ** 2)','I(treat * r)','I(treat * (r ** 2))','Intercept'])\n",
    "ncr1d2.rename_covariates({\n",
    "    'I(r ** 2)':'R^2', 'I(treat * (r ** 2))':'T x R^2', 'I(treat * r)':'T x R',\n",
    "    'r':'R','treat':'T'})\n",
    "ncr1d2.show_degrees_of_freedom(False)\n",
    "ncr1d2.add_custom_notes(['Robust standard errors (HC0)'])\n",
    "ncr1d2.show_model_numbers(False)\n",
    "ncr1d2.title('Estimated effects on Negative Comment Ratio (second-degree polynomial)')\n",
    "ncr1d2\n",
    "\n",
    "# Latex output\n",
    "# print(ncr1d2.render_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87dadd7",
   "metadata": {
    "id": "a7d5357c"
   },
   "source": [
    "$sNCR(h)$ summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df14e2a3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 519
    },
    "id": "a47cc774",
    "outputId": "99a754e6-711b-406f-e2bf-6abb3caa26d0",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Summaries\n",
    "ncr1d2 = Stargazer(d2[:6])\n",
    "ncr1d2.dependent_variable_name('Dependent Variable: Somewhat Negative Comment Ratio')\n",
    "ncr1d2.custom_columns([f'h = {h}' for h in hours], [1]*6)\n",
    "ncr1d2.covariate_order(['treat','r','I(r ** 2)','I(treat * r)','I(treat * (r ** 2))','Intercept'])\n",
    "ncr1d2.rename_covariates({\n",
    "    'I(r ** 2)':'R^2', 'I(treat * (r ** 2))':'T x R^2', 'I(treat * r)':'T x R',\n",
    "    'r':'R','treat':'T'})\n",
    "ncr1d2.show_degrees_of_freedom(False)\n",
    "ncr1d2.add_custom_notes(['Robust standard errors (HC0)'])\n",
    "ncr1d2.show_model_numbers(False)\n",
    "ncr1d2.title('Estimated effects on Somewhat Negative Comment Ratio (second-degree polynomial)')\n",
    "ncr1d2\n",
    "\n",
    "# Latex output\n",
    "# print(ncr1d2.render_latex())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae09fd6",
   "metadata": {},
   "source": [
    "### 4.3. Robustness checks\n",
    "#### 4.3.1. Control for president"
   ]
  },
  {
   "cell_type": "raw",
   "id": "84b92760",
   "metadata": {},
   "source": [
    "# Try controlling for president\n",
    "formula = 'ncr1Post12 ~ treat + president + I(treat*president) + ' \\\n",
    "    + 'r'# + I(r*treat) + I(r*president) + I(r*treat*president)'\n",
    "d = df[df['post12CommentsNum'] > 30]\n",
    "\n",
    "# Fit\n",
    "m = sm.OLS.from_formula(formula, d).fit()\n",
    "m.summary(alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f33cb6b5",
   "metadata": {
    "id": "f33cb6b5"
   },
   "source": [
    "### 4.4. Visualizations\n",
    "Linear and quadratic RDD for $NCR(12)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d455003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linrear and quadratic models\n",
    "l, q = d1[0], d2[0]\n",
    "\n",
    "# Data and predictions for lines\n",
    "t = pd.DataFrame({'r':df.loc[mask, 'r'],\n",
    "                  'l':d1[0].fittedvalues.values,\n",
    "                  'q':d2[0].fittedvalues.values})\n",
    "t['treat'] = (t['r'] > 0).astype(int)\n",
    "\n",
    "# Data for scatter\n",
    "bin_length = 4\n",
    "s = df.loc[mask, ['ncr1Post12','r']].copy()\n",
    "s['bin'] = (s['r'].div(60 * 60) / bin_length).apply(lambda x: floor(x))\n",
    "s = s.groupby('bin')['ncr1Post12'].mean().reset_index(name='mean')\n",
    "s['bin'] = s['bin'].multiply(bin_length * 60 * 60)\n",
    "\n",
    "# Initialize figure\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(14)\n",
    "\n",
    "# Plot model on each axis\n",
    "for i, ax in enumerate(axs):\n",
    "    # Plot linear model\n",
    "    if i == 0:\n",
    "        series = 'l'\n",
    "    else:\n",
    "        series = 'q'\n",
    "    # Lines\n",
    "    ax.plot(t.loc[t['treat'].eq(0), 'r'], t.loc[t['treat'].eq(0), series], color='C1')\n",
    "    ax.plot(t.loc[t['treat'].eq(1), 'r'], t.loc[t['treat'].eq(1), series], color='C1')\n",
    "    # Scatter\n",
    "    ax.scatter(s['bin'], s['mean'], color='C0', alpha=0.5)\n",
    "    # Shaded regions\n",
    "    ax.axvspan(xmin=0, xmax=24*60*60, color='gray', alpha=0.3)\n",
    "    ax.axvspan(xmin=-12*60*60, xmax=0, color='C0', alpha=0.3)\n",
    "    # X&Y axes\n",
    "    ax.set_xticks(np.arange(-5*24*60*60, 6*24*60*60+1, 24 * 60 * 60))\n",
    "    ax.set_xticklabels(np.arange(-5*24, 6*24+1, 24), rotation=45)\n",
    "    ax.set_xlim(-5*24*60*60, 6*24*60*60)\n",
    "    ax.set_ylim(0, 0.7)\n",
    "    # Labels\n",
    "    title = {'l':'First-degree polynomial','q':'Second-degree polynomial'}\n",
    "    ax.set_title(f'{title[series]}')\n",
    "    ax.set_xlabel('Hours until policy')\n",
    "    ax.set_ylabel('Negative Comment Ration (h=12)')\n",
    "    ax.grid(which='major', axis='x')\n",
    "# Save and show\n",
    "if 'google.colab' not in sys.modules:\n",
    "    plt.savefig('../../fig/fig_d1d2.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c708f391",
   "metadata": {
    "id": "c708f391"
   },
   "source": [
    "All linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2885f76",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig, axs = plt.subplots(nrows=6, ncols=2)\n",
    "fig.set_figheight(20)\n",
    "fig.set_figwidth(14)\n",
    "\n",
    "# Plot within each axis\n",
    "for i, ax_row in enumerate(axs):\n",
    "    # Left-right plots\n",
    "    for j, ax in enumerate(ax_row):\n",
    "        if j == 0:\n",
    "            outcome = f'ncr1{windows[i]}'\n",
    "            dotColor = 'blue'\n",
    "            ax.set_ylabel(f'NCR(h = {hours[i]})')\n",
    "            model = d1[i]\n",
    "        else:\n",
    "            outcome = f'ncr2{windows[i]}'\n",
    "            dotColor = 'lightblue'\n",
    "            ax.set_ylabel(f'sNCR(h = {hours[i]})')\n",
    "            model = d1[6+i]\n",
    "        # Masks\n",
    "        mask = df['post12CommentsNum'].gt(0) & df[outcome].notna()\n",
    "        # Line plots\n",
    "        t = df.loc[mask, ['treat','r']].assign(pred = model.fittedvalues)\n",
    "        ax.plot(t.loc[t['treat'].eq(0), 'r'], t.loc[t['treat'].eq(0), 'pred'], color='C1')\n",
    "        ax.plot(t.loc[t['treat'].eq(1), 'r'], t.loc[t['treat'].eq(1), 'pred'], color='C1')\n",
    "        # Scatter plots\n",
    "        s = df[mask].copy()\n",
    "        s['bin'] = (s['r'].div(4*60*60)).apply(lambda x: floor(x))\n",
    "        s = s.groupby('bin')[outcome].mean().reset_index(name='mean')\n",
    "        s['bin'] = s['bin'] * (4*60*60)\n",
    "        ax.scatter(x=s['bin'], y=s['mean'], color='C0', alpha=0.5)\n",
    "        # Shades\n",
    "        ax.axvspan(xmin=0, xmax=24*60*60, color='gray', alpha=0.3)\n",
    "        ax.axvspan(xmin=-hours[i]*60*60, xmax=0, color='C0', alpha=0.3)\n",
    "        # Axes\n",
    "        ax.set_ylim(0, 0.7)\n",
    "        ax.set_xticks(np.arange(-5*24*60*60, 6*24*60*60+1, 24*60*60))\n",
    "        ax.set_xticklabels(np.arange(-5*24, 6*24+1, 24))\n",
    "        ax.grid(which='major', axis='x')\n",
    "        if i == 0:\n",
    "            ax.set_title({0:'Negative Comment Ratio',1:'Somewhat Negative Comment Ratio'}[j])\n",
    "        if i == 5:\n",
    "            ax.set_xlabel('Hours until policy')\n",
    "# Show & save\n",
    "if 'google.colab' not in sys.modules:\n",
    "    plt.savefig('../../fig/fig_res_d1all.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de1037d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6de1037d",
    "outputId": "09c5ff88-652f-4e1f-9f48-ebf0723c76e9",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Initialize figure\n",
    "fig, axs = plt.subplots(nrows=6, ncols=2)\n",
    "fig.set_figheight(20)\n",
    "fig.set_figwidth(14)\n",
    "\n",
    "# Plot within each axis\n",
    "for i, ax_row in enumerate(axs):\n",
    "    # Left-right plots\n",
    "    for j, ax in enumerate(ax_row):\n",
    "        if j == 0:\n",
    "            outcome = f'ncr1{windows[i]}'\n",
    "            dotColor = 'blue'\n",
    "            ax.set_ylabel(f'NCR(h = {hours[i]})')\n",
    "            model = d2[i]\n",
    "        else:\n",
    "            outcome = f'ncr2{windows[i]}'\n",
    "            dotColor = 'lightblue'\n",
    "            ax.set_ylabel(f'sNCR(h = {hours[i]})')\n",
    "            model = d2[6+i]\n",
    "        # Masks\n",
    "        mask = df['post12CommentsNum'].gt(0) & df[outcome].notna()\n",
    "        # Line plots\n",
    "        t = df.loc[mask, ['treat','r']].assign(pred = model.fittedvalues)\n",
    "        ax.plot(t.loc[t['treat'].eq(0), 'r'], t.loc[t['treat'].eq(0), 'pred'], color='C1')\n",
    "        ax.plot(t.loc[t['treat'].eq(1), 'r'], t.loc[t['treat'].eq(1), 'pred'], color='C1')\n",
    "        # Scatter plots\n",
    "        s = df[mask].copy()\n",
    "        s['bin'] = (s['r'].div(4*60*60)).apply(lambda x: floor(x))\n",
    "        s = s.groupby('bin')[outcome].mean().reset_index(name='mean')\n",
    "        s['bin'] = s['bin'] * (4*60*60)\n",
    "        ax.scatter(x=s['bin'], y=s['mean'], color='C0', alpha=0.5)\n",
    "        # Shades\n",
    "        ax.axvspan(xmin=0, xmax=24*60*60, color='gray', alpha=0.3)\n",
    "        ax.axvspan(xmin=-hours[i]*60*60, xmax=0, color='C0', alpha=0.3)\n",
    "        # Axes\n",
    "        ax.set_ylim(0, 0.7)\n",
    "        ax.set_xticks(np.arange(-5*24*60*60, 6*24*60*60+1, 24*60*60))\n",
    "        ax.set_xticklabels(np.arange(-5*24, 6*24+1, 24))\n",
    "        ax.grid(which='major', axis='x')\n",
    "        if i == 0:\n",
    "            ax.set_title({0:'Negative Comment Ratio',1:'Somewhat Negative Comment Ratio'}[j])\n",
    "        if i == 5:\n",
    "            ax.set_xlabel('Hours until policy')\n",
    "# Show & save\n",
    "if 'google.colab' not in sys.modules:\n",
    "    plt.savefig('../../fig/fig_res_d2all.png', dpi=200, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc4bffd",
   "metadata": {},
   "source": [
    "Comparing linear to quadratic models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391592e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Goodness of fit\n",
    "t = pd.DataFrame(\n",
    "    {\n",
    "        'd1R2a':[m.rsquared_adj for m in d1], 'd2R2a':[m.rsquared_adj for m in d2],\n",
    "        'd1bic':[m.bic for m in d1], 'd2bic':[m.bic for m in d2],\n",
    "        'd1aic':[m.aic for m in d1], 'd2aic':[m.aic for m in d2],\n",
    "    }\n",
    ")\n",
    "\n",
    "t.round(4)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "01_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
