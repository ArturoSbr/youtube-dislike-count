{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9a7606f",
   "metadata": {},
   "source": [
    "# Scrape YouTube data\n",
    "This notebook scrapes the general details of videos uploaded by multiple news channels between 2021-11-05 and 2021-11-15 as well as each video's details and comment sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af4aed9",
   "metadata": {},
   "source": [
    "## Environment\n",
    "Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1073101",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import json\n",
    "import pandas as pd\n",
    "from youtube import channel, video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beaf9d0c",
   "metadata": {},
   "source": [
    "Get API key from environment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94d7e73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "key = os.getenv('API_KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad8aac4",
   "metadata": {},
   "source": [
    "## Import list of News channels\n",
    "\n",
    "This data set is a handpicked list of news channels that:\n",
    "1. Are relevant (top 100 subscribed or viewed channels)\n",
    "1. Post political content in English\n",
    "1. Have open comment sections"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb5c0487",
   "metadata": {},
   "source": [
    "df = pd.read_csv('../../dat/top_news_channels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c94a7f",
   "metadata": {},
   "source": [
    "## 1. Build `channels` table\n",
    "\n",
    "NOTE @ 2021-03-14: This section has already been executed. Since the requests are expensive, it's best to just load the result."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b5d53b6f",
   "metadata": {},
   "source": [
    "# Initialize list\n",
    "data = []\n",
    "\n",
    "# Get channels' details\n",
    "for channelId in df['channelId'].values:\n",
    "    ch = channel(id=channelId, key=key)\n",
    "    data.append([channelId] + ch.get_info())\n",
    "\n",
    "\n",
    "# Write table\n",
    "df1 = pd.DataFrame(data=data, columns=['channelId','name','joined','views'])\n",
    "df1.to_csv('../../dat/channels.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "24d5f5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load result\n",
    "df1 = pd.read_csv('../../dat/channels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bf666a",
   "metadata": {},
   "source": [
    "## 2. Build `channelVideos` table\n",
    "\n",
    "NOTE @ 2021-03-15: This section has already been executed. Since the requests are expensive, it's best to just load the result.\n",
    "\n",
    "### 2.1. Pre-treatment videos\n",
    "Videos uploaded on or before 2021-11-09"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ef2e98ab",
   "metadata": {},
   "source": [
    "# Initialize list\n",
    "vids_pre = []\n",
    "\n",
    "# Pre-treatment videos\n",
    "for channelId in df1['channelId'].values:\n",
    "    ch = channel(id=channelId, key=key)\n",
    "    try:\n",
    "        videoIds = ch.get_videos(category=25, date0='2021-11-05T00:00:00', date1='2021-11-09T23:59:59')\n",
    "        for videoId in videoIds:\n",
    "            vids_pre.append([channelId, videoId, 0])\n",
    "    except:\n",
    "        print('Crashed on channel', channelId)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0338d1e0",
   "metadata": {},
   "source": [
    "### 2.2. Post-treatment videos\n",
    "Videos uploaded on or after 2021-11-11 (skip November 10th because the policy was gradually rolled out)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "29acd3ad",
   "metadata": {},
   "source": [
    "# Initialize list\n",
    "vids_post = []\n",
    "\n",
    "# Post-treatment videos\n",
    "for channelId in df1['channelId'].values:\n",
    "    ch = channel(id=channelId, key=key)\n",
    "    try:\n",
    "        videoIds = ch.get_videos(category=25, date0='2021-11-11T00:00:00', date1='2021-11-15T23:59:59')\n",
    "        for videoId in videoIds:\n",
    "            vids_post.append([channelId, videoId, 1])\n",
    "    except:\n",
    "        print('Crashed on channel', channelId)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f5d270",
   "metadata": {},
   "source": [
    "API quota ran out on `channelId = UCt-WqkTyKK1_70U4bb4k4lQ`."
   ]
  },
  {
   "cell_type": "raw",
   "id": "67c1886c",
   "metadata": {},
   "source": [
    "# Next index before crash\n",
    "idx = df1[df1['channelId'].eq('UCt-WqkTyKK1_70U4bb4k4lQ')].index[0]\n",
    "\n",
    "# Loop resumes\n",
    "for channelId in df1.iloc[idx:, 0]:\n",
    "    ch = channel(id=channelId, key=key)\n",
    "    try:\n",
    "        videoIds = ch.get_videos(category=25, date0='2021-11-11T00:00:00', date1='2021-11-15T23:59:59')\n",
    "        for videoId in videoIds:\n",
    "                vids_post.append([channelId, videoId, 1])\n",
    "    except:\n",
    "        print('Crashed on channel', channelId)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3a1baf",
   "metadata": {},
   "source": [
    "Export table"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6c5738b",
   "metadata": {},
   "source": [
    "df2 = pd.DataFrame(data=vids_pre + vids_post, columns=['channelId','videoId','treat'])\n",
    "df2.to_csv('../../dat/videos.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc54e778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load result\n",
    "df2 = pd.read_csv('../../dat/videos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe78932f",
   "metadata": {},
   "source": [
    "## 3. Build `videoDetails` table\n",
    "\n",
    "Get the details of each video (title, description, duration, definition, etc.). These data will be used as controls.\n",
    "\n",
    "NOTE @ 2021-03-15: This section has already been executed. Since the requests are expensive, it's best to just load the result."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d70c9e3a",
   "metadata": {},
   "source": [
    "# Initialize list\n",
    "data = []\n",
    "\n",
    "# Loop videos\n",
    "for videoId in df2['videoId'].values:\n",
    "    try:\n",
    "        vid = video(id=videoId, key=key).get_details()\n",
    "        data.append([videoId] + list(vid.values()))\n",
    "    except:\n",
    "        print('Crashed on videoId', videoId)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572db078",
   "metadata": {},
   "source": [
    "Export table"
   ]
  },
  {
   "cell_type": "raw",
   "id": "41f7f818",
   "metadata": {},
   "source": [
    "df3 = pd.DataFrame(data=data, columns=['videoId'] + list(vid.keys()))\n",
    "df3.to_csv('../../dat/videoDetails.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "33234500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load result\n",
    "df3 = pd.read_csv('../../dat/videoDetails.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a18de8",
   "metadata": {},
   "source": [
    "## 4. Build `videoComments` table"
   ]
  },
  {
   "cell_type": "raw",
   "id": "32b9bf90",
   "metadata": {},
   "source": [
    "for videoId in df2['videoId'].values:\n",
    "    comments = video(id=videoId, key=key).get_comments()\n",
    "    if len(comments) > 0:\n",
    "        json.dump({videoId:comments}, open('../../dat/comments/' + videoId + '.json', 'w'))\n",
    "    else:\n",
    "        # Manual check\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8f2af3",
   "metadata": {},
   "source": [
    "- Quota Exceeded on `videoId = '_laKJi8Xwh8'`\n",
    "- Quota Exceeded on `videoId = 'OzRR6ROQ-mA'`\n",
    "- Quota Exceeded on `videoId = ''`"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f6937cc4",
   "metadata": {},
   "source": [
    "# Resume from crash\n",
    "idx = df2.loc[df2['videoId'].eq('OzRR6ROQ-mA')].index[0]\n",
    "\n",
    "for videoId in df2.iloc[idx:, 1].values:\n",
    "    comments = video(id=videoId, key=key).get_comments()\n",
    "    if len(comments) > 0:\n",
    "        json.dump({videoId:comments}, open('../../dat/comments/' + videoId + '.json', 'w'))\n",
    "    else:\n",
    "        # Manual check\n",
    "        print(videoId)\n",
    "        break"
   ]
  },
  {
   "cell_type": "raw",
   "id": "67a42357",
   "metadata": {},
   "source": [
    "comdis = ['AoLgaqj9Q7s','wZDvWH45BUQ','UAtSE-ytvk4','cdDUfKHerGI','e44OO1DqImk','oKD0YkxdfYA','gIbiEzje_mo',\n",
    "          'heIGpJU3WyI','']\n",
    "nocoms = ['SQ1r_Y_nzvo','9Ok5KL-aP2k','azGUy3vuIt0','L4I6A5pez_U','Nq5007kgzuA','dQQPAbD6HZk','G1kcJ9FqDhg',\n",
    "          'v2_hhy9lwLE','WyXBoDs5deQ','DZyGvWSaLCg','w59DwtY6w-w','Gew40t1tWgQ','Ot4zdjZ1klY','3eV3esbc3W0',\n",
    "          'MrAIdRND8Gw','wpu43o7dkg8','Ewjm0hTh8FQ','Zy2iGWuc3Q0','dfOxjKX2ouM','3lUPwRcgL3s','Ldm2EMUwrpc',\n",
    "          '']\n",
    "errors = ['vQNl8PpcSHw','bu7wwMIrxak','kujtF7tZ1Zk','cdDUfKHerGI','sKzgl4KTbhk','jzyCqHYIkvE','N2A4eI3xXWQ']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8909440e",
   "metadata": {},
   "source": [
    "Read json files and filter by days after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d97b28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df2, df3[['videoId','publishedAt']], on='videoId')\n",
    "df['publishedAt'] = df['publishedAt'].str[:10]\n",
    "t = df.groupby('publishedAt').size().reset_index(name='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb8314d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t=3:  452 pre and 592 post\n",
      "t=2:  612 pre and 714 post\n",
      "t=1:  831 pre and 899 post\n"
     ]
    }
   ],
   "source": [
    "print('t=3: ', 200 + 136 + 116, 'pre and', 229 + 207 + 156, 'post')\n",
    "print('t=2: ', 200 + 136 + 116 + 160, 'pre and', 229 + 207 + 156 + 122, 'post')\n",
    "print('t=1: ', 200 + 136 + 116 + 160 + 219, 'pre and', 229 + 207 + 156 + 122 + 185, 'post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc88b557",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0091324200913243"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "221/219"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
